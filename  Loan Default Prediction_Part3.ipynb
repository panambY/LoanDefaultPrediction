{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d67a817043afb7153c053a561d29ae0bb37cd578"
      },
      "cell_type": "code",
      "source": "# I will use in this Kernel the step-by-step process of Will Koehrsen.\n# I won't use everything, but most of them.\n# This project at in GitHub repository: https://github.com/WillKoehrsen/machine-learning-project-walkthrough",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# # Imports\n\n# Pandas and numpy for data manipulation\nimport pandas as pd\nimport numpy as np\n\n# No warnings about setting value on copy of slice\npd.options.mode.chained_assignment = None\n\n# Display up to 60 columns of a dataframe\npd.set_option('display.max_columns', 60)\n\n# Matplotlib visualization\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Set default font size\nplt.rcParams['font.size'] = 24\n\n# Internal ipython tool for setting figure size\nfrom IPython.core.pylabtools import figsize\n\n# Seaborn for visualization\nimport seaborn as sns\nsns.set(font_scale = 2)\n\n# Splitting data into training and testing\nfrom sklearn.model_selection import train_test_split",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# # # Data Cleaning and Formatting\n\n# # Load in the Data and Examine\n\n# Read in data into a dataframe \ndata = pd.read_csv('../input/train_v2.csv')\n\n# Display top of dataframe\ndata.head()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (135,204,274,417) have mixed types. Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n",
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "   id   f1  f2        f3    f4  f5     f6      f7      f8      f9     f10  \\\n0   1  126  10  0.686842  1100   3  13699  7201.0  4949.0  126.75  126.03   \n1   2  121  10  0.782776  1100   3  84645   240.0  1625.0  123.52  121.35   \n2   3  126  10  0.500080  1100   3  83607  1800.0  1527.0  127.76  126.49   \n3   4  134  10  0.439874  1100   3  82642  7542.0  1730.0  132.94  133.58   \n4   5  109   9  0.502749  2900   4  79124    89.0   491.0  122.72  112.77   \n\n   f13     f14     f15      f16     f17     f18     f19     f20     f21  \\\n0    7  0.7607  0.7542   612922  0.7236  0.7236  0.5171  0.7236  0.8476   \n1    7  0.6555  0.6555   245815  0.6341  0.6341  0.3909  0.6667  0.6903   \n2    7  0.7542  0.7542  1385872  0.7542  0.7542  0.5508  0.7542  0.8091   \n3    7  0.8017  0.7881   704687  0.7881  0.7881  0.5923  0.7881  0.8230   \n4    6  0.5263  0.5263    51985  0.5263  0.5263  0.3044  0.5405  0.5556   \n\n      f22           f23  f24  f25        f26   f27   f28     f29     f30  \\\n0  0.7876  1.097851e+09   89   66   998046.0  89.0  89.0   89.00   89.00   \n1  0.6903  8.449459e+08   78   50   754416.0  78.0  78.0   78.00   78.00   \n2  0.7807  1.308478e+09   89   54  1037651.0  89.0  89.0  100.43   94.37   \n3  0.8158  1.472752e+09   93   55  1115721.0  93.0  93.0  114.63  102.92   \n4  0.5455  1.442916e+09   60   21   536400.0  60.0  60.0   60.00   60.00   \n\n    f31  ...      f750      f751    f752    f753    f754    f755      f756  \\\n0  89.0  ...    2.3451  0.030594  1.7418  1.5271  0.8474  0.4715  0.028362   \n1  78.0  ...    1.5666  0.120442  1.1963  1.0322  0.4843  0.2389  0.130160   \n2  89.0  ...    4.5627  0.226336  3.3277  3.4166  1.8321  0.9979  0.103307   \n3  93.0  ...    1.6899  0.054630  1.3748  1.3421  0.7982  0.4810  0.081205   \n4  60.0  ...   11.9179  0.085330  7.2175  6.2262  3.1446  1.6149  0.074286   \n\n      f757     f758    f759      f760     f761     f762    f763  f764  f765  \\\n0   3.1611   2.5162  2.0037  0.019636   4.4352   4.2676 -0.1524     1 -0.40   \n1   2.7659   1.9523  1.4059  0.115277   3.2763   2.7962 -0.3097     1 -0.17   \n2   6.8623   5.2963  4.1282  0.219729   8.1381   7.3269 -0.1909     1 -0.58   \n3   2.5571   2.0593  1.6653  0.056470   3.2516   3.0631 -0.1770     1 -0.75   \n4  15.9080  12.5688  9.9844  0.067540  17.5561  15.6079 -0.4444     1 -0.18   \n\n    f766   f767    f768   f769  f770  f771  f772  f773    f774    f775  f776  \\\n0 -0.560 -0.440 -0.6280  -3.14     5  2.14 -1.54  1.18  0.1833  0.7873     1   \n1 -0.275 -0.203 -0.2300  -1.38     6  0.54 -0.24  0.13  0.1926 -0.6787     1   \n2 -0.540 -0.572 -0.3985  -5.18    13  2.89 -1.73  1.04  0.2521  0.7258     1   \n3 -0.635 -0.745 -0.5100  -2.04     4  1.29 -0.89  0.66  0.2498  0.7119     1   \n4 -0.280 -0.182 -0.4277 -11.12    26  6.11 -3.82  2.51  0.2282 -0.5399     0   \n\n   f777  f778  loss  \n0     0     5     0  \n1     0     5     0  \n2     0     5     0  \n3     0     5     0  \n4     0     5     0  \n\n[5 rows x 771 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>f1</th>\n      <th>f2</th>\n      <th>f3</th>\n      <th>f4</th>\n      <th>f5</th>\n      <th>f6</th>\n      <th>f7</th>\n      <th>f8</th>\n      <th>f9</th>\n      <th>f10</th>\n      <th>f13</th>\n      <th>f14</th>\n      <th>f15</th>\n      <th>f16</th>\n      <th>f17</th>\n      <th>f18</th>\n      <th>f19</th>\n      <th>f20</th>\n      <th>f21</th>\n      <th>f22</th>\n      <th>f23</th>\n      <th>f24</th>\n      <th>f25</th>\n      <th>f26</th>\n      <th>f27</th>\n      <th>f28</th>\n      <th>f29</th>\n      <th>f30</th>\n      <th>f31</th>\n      <th>...</th>\n      <th>f750</th>\n      <th>f751</th>\n      <th>f752</th>\n      <th>f753</th>\n      <th>f754</th>\n      <th>f755</th>\n      <th>f756</th>\n      <th>f757</th>\n      <th>f758</th>\n      <th>f759</th>\n      <th>f760</th>\n      <th>f761</th>\n      <th>f762</th>\n      <th>f763</th>\n      <th>f764</th>\n      <th>f765</th>\n      <th>f766</th>\n      <th>f767</th>\n      <th>f768</th>\n      <th>f769</th>\n      <th>f770</th>\n      <th>f771</th>\n      <th>f772</th>\n      <th>f773</th>\n      <th>f774</th>\n      <th>f775</th>\n      <th>f776</th>\n      <th>f777</th>\n      <th>f778</th>\n      <th>loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>126</td>\n      <td>10</td>\n      <td>0.686842</td>\n      <td>1100</td>\n      <td>3</td>\n      <td>13699</td>\n      <td>7201.0</td>\n      <td>4949.0</td>\n      <td>126.75</td>\n      <td>126.03</td>\n      <td>7</td>\n      <td>0.7607</td>\n      <td>0.7542</td>\n      <td>612922</td>\n      <td>0.7236</td>\n      <td>0.7236</td>\n      <td>0.5171</td>\n      <td>0.7236</td>\n      <td>0.8476</td>\n      <td>0.7876</td>\n      <td>1.097851e+09</td>\n      <td>89</td>\n      <td>66</td>\n      <td>998046.0</td>\n      <td>89.0</td>\n      <td>89.0</td>\n      <td>89.00</td>\n      <td>89.00</td>\n      <td>89.0</td>\n      <td>...</td>\n      <td>2.3451</td>\n      <td>0.030594</td>\n      <td>1.7418</td>\n      <td>1.5271</td>\n      <td>0.8474</td>\n      <td>0.4715</td>\n      <td>0.028362</td>\n      <td>3.1611</td>\n      <td>2.5162</td>\n      <td>2.0037</td>\n      <td>0.019636</td>\n      <td>4.4352</td>\n      <td>4.2676</td>\n      <td>-0.1524</td>\n      <td>1</td>\n      <td>-0.40</td>\n      <td>-0.560</td>\n      <td>-0.440</td>\n      <td>-0.6280</td>\n      <td>-3.14</td>\n      <td>5</td>\n      <td>2.14</td>\n      <td>-1.54</td>\n      <td>1.18</td>\n      <td>0.1833</td>\n      <td>0.7873</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>121</td>\n      <td>10</td>\n      <td>0.782776</td>\n      <td>1100</td>\n      <td>3</td>\n      <td>84645</td>\n      <td>240.0</td>\n      <td>1625.0</td>\n      <td>123.52</td>\n      <td>121.35</td>\n      <td>7</td>\n      <td>0.6555</td>\n      <td>0.6555</td>\n      <td>245815</td>\n      <td>0.6341</td>\n      <td>0.6341</td>\n      <td>0.3909</td>\n      <td>0.6667</td>\n      <td>0.6903</td>\n      <td>0.6903</td>\n      <td>8.449459e+08</td>\n      <td>78</td>\n      <td>50</td>\n      <td>754416.0</td>\n      <td>78.0</td>\n      <td>78.0</td>\n      <td>78.00</td>\n      <td>78.00</td>\n      <td>78.0</td>\n      <td>...</td>\n      <td>1.5666</td>\n      <td>0.120442</td>\n      <td>1.1963</td>\n      <td>1.0322</td>\n      <td>0.4843</td>\n      <td>0.2389</td>\n      <td>0.130160</td>\n      <td>2.7659</td>\n      <td>1.9523</td>\n      <td>1.4059</td>\n      <td>0.115277</td>\n      <td>3.2763</td>\n      <td>2.7962</td>\n      <td>-0.3097</td>\n      <td>1</td>\n      <td>-0.17</td>\n      <td>-0.275</td>\n      <td>-0.203</td>\n      <td>-0.2300</td>\n      <td>-1.38</td>\n      <td>6</td>\n      <td>0.54</td>\n      <td>-0.24</td>\n      <td>0.13</td>\n      <td>0.1926</td>\n      <td>-0.6787</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>126</td>\n      <td>10</td>\n      <td>0.500080</td>\n      <td>1100</td>\n      <td>3</td>\n      <td>83607</td>\n      <td>1800.0</td>\n      <td>1527.0</td>\n      <td>127.76</td>\n      <td>126.49</td>\n      <td>7</td>\n      <td>0.7542</td>\n      <td>0.7542</td>\n      <td>1385872</td>\n      <td>0.7542</td>\n      <td>0.7542</td>\n      <td>0.5508</td>\n      <td>0.7542</td>\n      <td>0.8091</td>\n      <td>0.7807</td>\n      <td>1.308478e+09</td>\n      <td>89</td>\n      <td>54</td>\n      <td>1037651.0</td>\n      <td>89.0</td>\n      <td>89.0</td>\n      <td>100.43</td>\n      <td>94.37</td>\n      <td>89.0</td>\n      <td>...</td>\n      <td>4.5627</td>\n      <td>0.226336</td>\n      <td>3.3277</td>\n      <td>3.4166</td>\n      <td>1.8321</td>\n      <td>0.9979</td>\n      <td>0.103307</td>\n      <td>6.8623</td>\n      <td>5.2963</td>\n      <td>4.1282</td>\n      <td>0.219729</td>\n      <td>8.1381</td>\n      <td>7.3269</td>\n      <td>-0.1909</td>\n      <td>1</td>\n      <td>-0.58</td>\n      <td>-0.540</td>\n      <td>-0.572</td>\n      <td>-0.3985</td>\n      <td>-5.18</td>\n      <td>13</td>\n      <td>2.89</td>\n      <td>-1.73</td>\n      <td>1.04</td>\n      <td>0.2521</td>\n      <td>0.7258</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>134</td>\n      <td>10</td>\n      <td>0.439874</td>\n      <td>1100</td>\n      <td>3</td>\n      <td>82642</td>\n      <td>7542.0</td>\n      <td>1730.0</td>\n      <td>132.94</td>\n      <td>133.58</td>\n      <td>7</td>\n      <td>0.8017</td>\n      <td>0.7881</td>\n      <td>704687</td>\n      <td>0.7881</td>\n      <td>0.7881</td>\n      <td>0.5923</td>\n      <td>0.7881</td>\n      <td>0.8230</td>\n      <td>0.8158</td>\n      <td>1.472752e+09</td>\n      <td>93</td>\n      <td>55</td>\n      <td>1115721.0</td>\n      <td>93.0</td>\n      <td>93.0</td>\n      <td>114.63</td>\n      <td>102.92</td>\n      <td>93.0</td>\n      <td>...</td>\n      <td>1.6899</td>\n      <td>0.054630</td>\n      <td>1.3748</td>\n      <td>1.3421</td>\n      <td>0.7982</td>\n      <td>0.4810</td>\n      <td>0.081205</td>\n      <td>2.5571</td>\n      <td>2.0593</td>\n      <td>1.6653</td>\n      <td>0.056470</td>\n      <td>3.2516</td>\n      <td>3.0631</td>\n      <td>-0.1770</td>\n      <td>1</td>\n      <td>-0.75</td>\n      <td>-0.635</td>\n      <td>-0.745</td>\n      <td>-0.5100</td>\n      <td>-2.04</td>\n      <td>4</td>\n      <td>1.29</td>\n      <td>-0.89</td>\n      <td>0.66</td>\n      <td>0.2498</td>\n      <td>0.7119</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>109</td>\n      <td>9</td>\n      <td>0.502749</td>\n      <td>2900</td>\n      <td>4</td>\n      <td>79124</td>\n      <td>89.0</td>\n      <td>491.0</td>\n      <td>122.72</td>\n      <td>112.77</td>\n      <td>6</td>\n      <td>0.5263</td>\n      <td>0.5263</td>\n      <td>51985</td>\n      <td>0.5263</td>\n      <td>0.5263</td>\n      <td>0.3044</td>\n      <td>0.5405</td>\n      <td>0.5556</td>\n      <td>0.5455</td>\n      <td>1.442916e+09</td>\n      <td>60</td>\n      <td>21</td>\n      <td>536400.0</td>\n      <td>60.0</td>\n      <td>60.0</td>\n      <td>60.00</td>\n      <td>60.00</td>\n      <td>60.0</td>\n      <td>...</td>\n      <td>11.9179</td>\n      <td>0.085330</td>\n      <td>7.2175</td>\n      <td>6.2262</td>\n      <td>3.1446</td>\n      <td>1.6149</td>\n      <td>0.074286</td>\n      <td>15.9080</td>\n      <td>12.5688</td>\n      <td>9.9844</td>\n      <td>0.067540</td>\n      <td>17.5561</td>\n      <td>15.6079</td>\n      <td>-0.4444</td>\n      <td>1</td>\n      <td>-0.18</td>\n      <td>-0.280</td>\n      <td>-0.182</td>\n      <td>-0.4277</td>\n      <td>-11.12</td>\n      <td>26</td>\n      <td>6.11</td>\n      <td>-3.82</td>\n      <td>2.51</td>\n      <td>0.2282</td>\n      <td>-0.5399</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 771 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "59f931574dd75b9b1b750403420b04c3216cef56"
      },
      "cell_type": "code",
      "source": "data.shape",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "(105471, 771)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0afdcffbcd53eb30140dc2c8bcd922f9b7cef9d2"
      },
      "cell_type": "code",
      "source": "# # Data Types and Missing Values\n\n# See the column data types and non-missing values\ndata.info()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 105471 entries, 0 to 105470\nColumns: 771 entries, id to loss\ndtypes: float64(653), int64(99), object(19)\nmemory usage: 620.4+ MB\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e66dd9afd8d014c48077843b26f304a9c8e8c130"
      },
      "cell_type": "code",
      "source": "data.select_dtypes(include=['object']).head()",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "                f137                     f138            f206  \\\n0   8090000000000000    754485076006959972352   3200000000000   \n1      2250000000000        15300000000000000    392000000000   \n2    186000000000000      6910365323840000000  23700000000000   \n3  44500000000000000  11225194901267999096832     16098514954   \n4        52152926246          108000000000000    442000000000   \n\n                 f207              f276                   f277           f338  \\\n0   38600000000000000  7900000000000000  683091368180479950848  7610000000000   \n1    1690000000000000    92300000000000    2140000000000000000      796594176   \n2  389000000000000000    10300000000000      69200000000000000   461000000000   \n3      35000000000000    22200000000000     295000000000000000  1330000000000   \n4    1870000000000000     3630000000000      23100000000000000  2240000000000   \n\n                             f390                                     f391  \\\n0   10370164393071999997033054208   13621142007705000132589703585884798976   \n1    5098137566366599989877014528    5366154527659000357778647583412977664   \n2   26400269714792999161039945728   36117033568522998807722429270944907264   \n3    9333818143939599917454983168   12638526060843999893906772076814925824   \n4  196004669899870011305513451520  428213273484070002013091334592080642048   \n\n           f419             f420                       f469  \\\n0  137000000000  511000000000000   569877634360569973702656   \n1       9483264       1593188352         107000000000000000   \n2   36051866452   63500000000000      313319151143610023936   \n3    5621900678    9380000000000  2641626213765599994052608   \n4  279000000000  659000000000000             68300000000000   \n\n                               f472                      f534  \\\n0   3427303293502300223465356001280  240811094251680005357568   \n1            9894337169928600158208     251470350285930004480   \n2       222812827058929985669562368     116067852739909992448   \n3  24452856014536001129152839155712     202899352692079984640   \n4                922000000000000000        654000000000000000   \n\n                              f537                            f626  \\\n0  1185103615651699994464937312256   11724173453590999285553430528   \n1      161196782629860003268263936    6391495663130699779035627520   \n2       61668865475731997253959680   36420952401170000260810932224   \n3      126293716597939998795235328   15267506423634001098621059072   \n4          89341826582645997305856  238204359524660008028924280832   \n\n                                      f627                   f695  \\\n0   16027029142402000396838501389877379072    8700000000000000000   \n1    7158933769610900052770065343332745216    5890000000000000000   \n2   56027915541865997900093655676589441024   24512111987574001664   \n3   24362045267421999852972382580757233664    9660000000000000000   \n4  550170020491249969340152709153269219328  108505460071560003584   \n\n                   f698  \n0   8010000000000000000  \n1   5030000000000000000  \n2  19855991371293999104  \n3   6960000000000000000  \n4  94766610066210996224  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f137</th>\n      <th>f138</th>\n      <th>f206</th>\n      <th>f207</th>\n      <th>f276</th>\n      <th>f277</th>\n      <th>f338</th>\n      <th>f390</th>\n      <th>f391</th>\n      <th>f419</th>\n      <th>f420</th>\n      <th>f469</th>\n      <th>f472</th>\n      <th>f534</th>\n      <th>f537</th>\n      <th>f626</th>\n      <th>f627</th>\n      <th>f695</th>\n      <th>f698</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8090000000000000</td>\n      <td>754485076006959972352</td>\n      <td>3200000000000</td>\n      <td>38600000000000000</td>\n      <td>7900000000000000</td>\n      <td>683091368180479950848</td>\n      <td>7610000000000</td>\n      <td>10370164393071999997033054208</td>\n      <td>13621142007705000132589703585884798976</td>\n      <td>137000000000</td>\n      <td>511000000000000</td>\n      <td>569877634360569973702656</td>\n      <td>3427303293502300223465356001280</td>\n      <td>240811094251680005357568</td>\n      <td>1185103615651699994464937312256</td>\n      <td>11724173453590999285553430528</td>\n      <td>16027029142402000396838501389877379072</td>\n      <td>8700000000000000000</td>\n      <td>8010000000000000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2250000000000</td>\n      <td>15300000000000000</td>\n      <td>392000000000</td>\n      <td>1690000000000000</td>\n      <td>92300000000000</td>\n      <td>2140000000000000000</td>\n      <td>796594176</td>\n      <td>5098137566366599989877014528</td>\n      <td>5366154527659000357778647583412977664</td>\n      <td>9483264</td>\n      <td>1593188352</td>\n      <td>107000000000000000</td>\n      <td>9894337169928600158208</td>\n      <td>251470350285930004480</td>\n      <td>161196782629860003268263936</td>\n      <td>6391495663130699779035627520</td>\n      <td>7158933769610900052770065343332745216</td>\n      <td>5890000000000000000</td>\n      <td>5030000000000000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>186000000000000</td>\n      <td>6910365323840000000</td>\n      <td>23700000000000</td>\n      <td>389000000000000000</td>\n      <td>10300000000000</td>\n      <td>69200000000000000</td>\n      <td>461000000000</td>\n      <td>26400269714792999161039945728</td>\n      <td>36117033568522998807722429270944907264</td>\n      <td>36051866452</td>\n      <td>63500000000000</td>\n      <td>313319151143610023936</td>\n      <td>222812827058929985669562368</td>\n      <td>116067852739909992448</td>\n      <td>61668865475731997253959680</td>\n      <td>36420952401170000260810932224</td>\n      <td>56027915541865997900093655676589441024</td>\n      <td>24512111987574001664</td>\n      <td>19855991371293999104</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>44500000000000000</td>\n      <td>11225194901267999096832</td>\n      <td>16098514954</td>\n      <td>35000000000000</td>\n      <td>22200000000000</td>\n      <td>295000000000000000</td>\n      <td>1330000000000</td>\n      <td>9333818143939599917454983168</td>\n      <td>12638526060843999893906772076814925824</td>\n      <td>5621900678</td>\n      <td>9380000000000</td>\n      <td>2641626213765599994052608</td>\n      <td>24452856014536001129152839155712</td>\n      <td>202899352692079984640</td>\n      <td>126293716597939998795235328</td>\n      <td>15267506423634001098621059072</td>\n      <td>24362045267421999852972382580757233664</td>\n      <td>9660000000000000000</td>\n      <td>6960000000000000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>52152926246</td>\n      <td>108000000000000</td>\n      <td>442000000000</td>\n      <td>1870000000000000</td>\n      <td>3630000000000</td>\n      <td>23100000000000000</td>\n      <td>2240000000000</td>\n      <td>196004669899870011305513451520</td>\n      <td>428213273484070002013091334592080642048</td>\n      <td>279000000000</td>\n      <td>659000000000000</td>\n      <td>68300000000000</td>\n      <td>922000000000000000</td>\n      <td>654000000000000000</td>\n      <td>89341826582645997305856</td>\n      <td>238204359524660008028924280832</td>\n      <td>550170020491249969340152709153269219328</td>\n      <td>108505460071560003584</td>\n      <td>94766610066210996224</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5e62f799ae387d53f80a3261f6ec2ead90cef0a4"
      },
      "cell_type": "code",
      "source": "# Statistics for each column\ndata.describe()",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "                  id             f1             f2             f3  \\\ncount  105471.000000  105471.000000  105471.000000  105471.000000   \nmean    52736.000000     134.603171       8.246883       0.499066   \nstd     30446.999458      14.725467       1.691535       0.288752   \nmin         1.000000     103.000000       1.000000       0.000006   \n25%     26368.500000     124.000000       8.000000       0.248950   \n50%     52736.000000     129.000000       9.000000       0.498267   \n75%     79103.500000     148.000000       9.000000       0.749494   \nmax    105471.000000     176.000000      11.000000       0.999994   \n\n                  f4             f5             f6             f7  \\\ncount  105471.000000  105471.000000  105471.000000  105289.000000   \nmean     2678.488874       7.354533   47993.704317    2974.336018   \nstd      1401.010943       5.151112   35677.136048    2546.551085   \nmin      1100.000000       1.000000       0.000000       1.000000   \n25%      1500.000000       4.000000   11255.000000     629.000000   \n50%      2200.000000       4.000000   76530.000000    2292.000000   \n75%      3700.000000      10.000000   80135.000000    4679.000000   \nmax      7900.000000      17.000000   88565.000000    9968.000000   \n\n                  f8             f9            f10            f13  \\\ncount  105370.000000  105471.000000  105471.000000  105471.000000   \nmean     2436.363718     134.555225     134.596862      11.349015   \nstd      2262.950221      13.824682      14.504043       3.669019   \nmin         1.000000     106.820000     103.140000       2.000000   \n25%       746.000000     124.290000     123.870000       9.000000   \n50%      1786.000000     128.460000     129.080000      11.000000   \n75%      3411.000000     149.080000     148.310000      13.000000   \nmax     11541.000000     172.950000     175.270000      40.000000   \n\n                 f14            f15           f16            f17  \\\ncount  105371.000000  105423.000000  1.054710e+05  105312.000000   \nmean        0.696120       0.678140  4.010386e+06       0.673572   \nstd         0.242829       0.241969  6.623236e+06       0.232733   \nmin         0.000000       0.000000  0.000000e+00       0.000000   \n25%         0.680000       0.661500  4.117930e+05       0.656000   \n50%         0.770500       0.754200  1.672764e+06       0.745800   \n75%         0.831900       0.815100  4.731222e+06       0.804900   \nmax         1.000000       1.000000  7.037873e+07       1.000000   \n\n                 f18            f19            f20            f21  \\\ncount  105448.000000  105448.000000  105011.000000  103631.000000   \nmean        0.649476       0.510736       0.685829       0.746194   \nstd         0.246958       0.173126       0.241082       0.237795   \nmin         0.000000       0.000000       0.000000       0.000000   \n25%         0.635600       0.432500       0.669400       0.729700   \n50%         0.736000       0.539200       0.761900       0.818200   \n75%         0.796700       0.627000       0.823000       0.876100   \nmax         1.000000       1.000000       1.000000       1.000000   \n\n                 f22           f23            f24            f25  \\\ncount  103773.000000  1.047730e+05  105471.000000  105471.000000   \nmean        0.726551  3.014404e+09      82.179803      63.420561   \nstd         0.233876  2.070153e+09      28.316093      32.431329   \nmin         0.000000  1.623600e+05       0.000000       0.000000   \n25%         0.710500  1.508475e+09      81.000000      45.000000   \n50%         0.798200  2.233947e+09      91.000000      65.000000   \n75%         0.855900  4.031443e+09      98.000000      84.000000   \nmax         1.000000  1.563049e+10     126.000000     184.000000   \n\n                f26            f27            f28            f29  \\\ncount  1.047730e+05  105471.000000  105471.000000  105471.000000   \nmean   1.108926e+06      92.134281      86.490683     103.850939   \nstd    3.015962e+05      36.904526      30.830152      40.968777   \nmin    1.230000e+02       0.000000       0.000000       0.000000   \n25%    9.267570e+05      84.000000      83.000000      91.000000   \n50%    1.115136e+06      94.780000      94.000000     108.000000   \n75%    1.293732e+06     104.000000     101.000000     128.750000   \nmax    2.603664e+06     218.730000     160.490000     220.630000   \n\n                 f30            f31      ...                 f750  \\\ncount  105471.000000  104773.000000      ...        104618.000000   \nmean       91.672933      90.045642      ...             8.115740   \nstd        32.681102      12.535453      ...            10.319706   \nmin         0.000000       1.000000      ...             0.000000   \n25%        87.000000      84.000000      ...             1.700900   \n50%        99.000000      92.000000      ...             4.261950   \n75%       109.890000      99.000000      ...            10.210900   \nmax       159.900000     126.000000      ...            91.821900   \n\n                f751           f752           f753           f754  \\\ncount  104013.000000  105469.000000  105469.000000  105469.000000   \nmean        0.138719       6.130018       5.500419       3.390325   \nstd         0.115468       8.121672       7.143152       4.685670   \nmin         0.000000       0.000000       0.000100       0.000000   \n25%         0.058420       1.202000       1.122200       0.595700   \n50%         0.083637       3.081600       2.840700       1.627000   \n75%         0.217172       7.569000       6.859100       4.152300   \nmax         0.500000      77.673100      68.652100      48.579400   \n\n                f755           f756           f757           f758  \\\ncount  105469.000000  105238.000000  104671.000000  104671.000000   \nmean        2.158617       0.119762      10.602136       8.782883   \nstd         3.163447       0.063974      12.899936      10.998444   \nmin         0.000000       0.000000       0.000000       0.000000   \n25%         0.323300       0.076388       2.535400       1.957400   \n50%         0.957600       0.103507       5.855800       4.711500   \n75%         2.595800       0.156381      13.316650      10.987400   \nmax        36.473500       0.497640     112.770300      95.343600   \n\n                f759           f760           f761           f762  \\\ncount  104671.000000  104137.000000  105313.000000  105313.000000   \nmean        7.341984       0.136195      12.921228      12.103488   \nstd         9.435965       0.112682      14.973088      14.151640   \nmin         0.000000       0.000000       0.000000       0.000000   \n25%         1.530850       0.056469       3.361800       3.055100   \n50%         3.830000       0.082008       7.564900       7.045500   \n75%         9.148000       0.219453      16.463500      15.448100   \nmax        82.293100       0.500000     127.346800     120.425000   \n\n                f763      f764           f765           f766           f767  \\\ncount  103631.000000  105471.0  105470.000000  105471.000000  105471.000000   \nmean       -0.253806       1.0      -0.471021      -0.476605      -0.471572   \nstd         0.237795       0.0       0.284702       0.194983       0.263993   \nmin        -1.000000       1.0      -0.970000      -0.950000      -0.963000   \n25%        -0.270300       1.0      -0.710000      -0.630000      -0.699000   \n50%        -0.181800       1.0      -0.500000      -0.480000      -0.480000   \n75%        -0.123900       1.0      -0.230000      -0.330000      -0.248000   \nmax         0.000000       1.0       0.000000       0.000000       0.000000   \n\n                f768           f769           f770           f771  \\\ncount  105471.000000  105471.000000  105471.000000  105471.000000   \nmean       -0.491973      -8.786110      17.422543       5.800976   \nstd         0.141869       9.684043      18.548936       6.508555   \nmin        -0.945000     -85.450000       2.000000       0.000000   \n25%        -0.575900     -11.530000       5.000000       1.480000   \n50%        -0.503100      -5.440000      11.000000       3.570000   \n75%        -0.420000      -2.390000      23.000000       7.700000   \nmax         0.000000       0.000000     168.000000      58.120000   \n\n                f772           f773           f774           f775  \\\ncount  105471.000000  105471.000000  104407.000000  103946.000000   \nmean       -4.246788       3.273059       0.233852       0.014797   \nstd         4.828265       3.766746       0.073578       1.039439   \nmin       -43.160000       0.000000       0.000000     -18.439600   \n25%        -5.700000       0.740000       0.198400      -0.704275   \n50%        -2.600000       1.990000       0.251800       0.375400   \n75%        -1.010000       4.440000       0.283600       0.737100   \nmax         0.000000      34.040000       0.473700      11.092000   \n\n                f776           f777           f778           loss  \ncount  105471.000000  105471.000000  105471.000000  105471.000000  \nmean        0.310246       0.322847     175.951589       0.799585  \nstd         0.462597       0.467567     298.294043       4.321120  \nmin         0.000000       0.000000       2.000000       0.000000  \n25%         0.000000       0.000000      19.000000       0.000000  \n50%         0.000000       0.000000      40.000000       0.000000  \n75%         1.000000       1.000000     104.000000       0.000000  \nmax         1.000000       1.000000    1212.000000     100.000000  \n\n[8 rows x 752 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>f1</th>\n      <th>f2</th>\n      <th>f3</th>\n      <th>f4</th>\n      <th>f5</th>\n      <th>f6</th>\n      <th>f7</th>\n      <th>f8</th>\n      <th>f9</th>\n      <th>f10</th>\n      <th>f13</th>\n      <th>f14</th>\n      <th>f15</th>\n      <th>f16</th>\n      <th>f17</th>\n      <th>f18</th>\n      <th>f19</th>\n      <th>f20</th>\n      <th>f21</th>\n      <th>f22</th>\n      <th>f23</th>\n      <th>f24</th>\n      <th>f25</th>\n      <th>f26</th>\n      <th>f27</th>\n      <th>f28</th>\n      <th>f29</th>\n      <th>f30</th>\n      <th>f31</th>\n      <th>...</th>\n      <th>f750</th>\n      <th>f751</th>\n      <th>f752</th>\n      <th>f753</th>\n      <th>f754</th>\n      <th>f755</th>\n      <th>f756</th>\n      <th>f757</th>\n      <th>f758</th>\n      <th>f759</th>\n      <th>f760</th>\n      <th>f761</th>\n      <th>f762</th>\n      <th>f763</th>\n      <th>f764</th>\n      <th>f765</th>\n      <th>f766</th>\n      <th>f767</th>\n      <th>f768</th>\n      <th>f769</th>\n      <th>f770</th>\n      <th>f771</th>\n      <th>f772</th>\n      <th>f773</th>\n      <th>f774</th>\n      <th>f775</th>\n      <th>f776</th>\n      <th>f777</th>\n      <th>f778</th>\n      <th>loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n      <td>105289.000000</td>\n      <td>105370.000000</td>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n      <td>105371.000000</td>\n      <td>105423.000000</td>\n      <td>1.054710e+05</td>\n      <td>105312.000000</td>\n      <td>105448.000000</td>\n      <td>105448.000000</td>\n      <td>105011.000000</td>\n      <td>103631.000000</td>\n      <td>103773.000000</td>\n      <td>1.047730e+05</td>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n      <td>1.047730e+05</td>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n      <td>104773.000000</td>\n      <td>...</td>\n      <td>104618.000000</td>\n      <td>104013.000000</td>\n      <td>105469.000000</td>\n      <td>105469.000000</td>\n      <td>105469.000000</td>\n      <td>105469.000000</td>\n      <td>105238.000000</td>\n      <td>104671.000000</td>\n      <td>104671.000000</td>\n      <td>104671.000000</td>\n      <td>104137.000000</td>\n      <td>105313.000000</td>\n      <td>105313.000000</td>\n      <td>103631.000000</td>\n      <td>105471.0</td>\n      <td>105470.000000</td>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n      <td>104407.000000</td>\n      <td>103946.000000</td>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n      <td>105471.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>52736.000000</td>\n      <td>134.603171</td>\n      <td>8.246883</td>\n      <td>0.499066</td>\n      <td>2678.488874</td>\n      <td>7.354533</td>\n      <td>47993.704317</td>\n      <td>2974.336018</td>\n      <td>2436.363718</td>\n      <td>134.555225</td>\n      <td>134.596862</td>\n      <td>11.349015</td>\n      <td>0.696120</td>\n      <td>0.678140</td>\n      <td>4.010386e+06</td>\n      <td>0.673572</td>\n      <td>0.649476</td>\n      <td>0.510736</td>\n      <td>0.685829</td>\n      <td>0.746194</td>\n      <td>0.726551</td>\n      <td>3.014404e+09</td>\n      <td>82.179803</td>\n      <td>63.420561</td>\n      <td>1.108926e+06</td>\n      <td>92.134281</td>\n      <td>86.490683</td>\n      <td>103.850939</td>\n      <td>91.672933</td>\n      <td>90.045642</td>\n      <td>...</td>\n      <td>8.115740</td>\n      <td>0.138719</td>\n      <td>6.130018</td>\n      <td>5.500419</td>\n      <td>3.390325</td>\n      <td>2.158617</td>\n      <td>0.119762</td>\n      <td>10.602136</td>\n      <td>8.782883</td>\n      <td>7.341984</td>\n      <td>0.136195</td>\n      <td>12.921228</td>\n      <td>12.103488</td>\n      <td>-0.253806</td>\n      <td>1.0</td>\n      <td>-0.471021</td>\n      <td>-0.476605</td>\n      <td>-0.471572</td>\n      <td>-0.491973</td>\n      <td>-8.786110</td>\n      <td>17.422543</td>\n      <td>5.800976</td>\n      <td>-4.246788</td>\n      <td>3.273059</td>\n      <td>0.233852</td>\n      <td>0.014797</td>\n      <td>0.310246</td>\n      <td>0.322847</td>\n      <td>175.951589</td>\n      <td>0.799585</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>30446.999458</td>\n      <td>14.725467</td>\n      <td>1.691535</td>\n      <td>0.288752</td>\n      <td>1401.010943</td>\n      <td>5.151112</td>\n      <td>35677.136048</td>\n      <td>2546.551085</td>\n      <td>2262.950221</td>\n      <td>13.824682</td>\n      <td>14.504043</td>\n      <td>3.669019</td>\n      <td>0.242829</td>\n      <td>0.241969</td>\n      <td>6.623236e+06</td>\n      <td>0.232733</td>\n      <td>0.246958</td>\n      <td>0.173126</td>\n      <td>0.241082</td>\n      <td>0.237795</td>\n      <td>0.233876</td>\n      <td>2.070153e+09</td>\n      <td>28.316093</td>\n      <td>32.431329</td>\n      <td>3.015962e+05</td>\n      <td>36.904526</td>\n      <td>30.830152</td>\n      <td>40.968777</td>\n      <td>32.681102</td>\n      <td>12.535453</td>\n      <td>...</td>\n      <td>10.319706</td>\n      <td>0.115468</td>\n      <td>8.121672</td>\n      <td>7.143152</td>\n      <td>4.685670</td>\n      <td>3.163447</td>\n      <td>0.063974</td>\n      <td>12.899936</td>\n      <td>10.998444</td>\n      <td>9.435965</td>\n      <td>0.112682</td>\n      <td>14.973088</td>\n      <td>14.151640</td>\n      <td>0.237795</td>\n      <td>0.0</td>\n      <td>0.284702</td>\n      <td>0.194983</td>\n      <td>0.263993</td>\n      <td>0.141869</td>\n      <td>9.684043</td>\n      <td>18.548936</td>\n      <td>6.508555</td>\n      <td>4.828265</td>\n      <td>3.766746</td>\n      <td>0.073578</td>\n      <td>1.039439</td>\n      <td>0.462597</td>\n      <td>0.467567</td>\n      <td>298.294043</td>\n      <td>4.321120</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>103.000000</td>\n      <td>1.000000</td>\n      <td>0.000006</td>\n      <td>1100.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>106.820000</td>\n      <td>103.140000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.623600e+05</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.230000e+02</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000100</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-1.000000</td>\n      <td>1.0</td>\n      <td>-0.970000</td>\n      <td>-0.950000</td>\n      <td>-0.963000</td>\n      <td>-0.945000</td>\n      <td>-85.450000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>-43.160000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-18.439600</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>26368.500000</td>\n      <td>124.000000</td>\n      <td>8.000000</td>\n      <td>0.248950</td>\n      <td>1500.000000</td>\n      <td>4.000000</td>\n      <td>11255.000000</td>\n      <td>629.000000</td>\n      <td>746.000000</td>\n      <td>124.290000</td>\n      <td>123.870000</td>\n      <td>9.000000</td>\n      <td>0.680000</td>\n      <td>0.661500</td>\n      <td>4.117930e+05</td>\n      <td>0.656000</td>\n      <td>0.635600</td>\n      <td>0.432500</td>\n      <td>0.669400</td>\n      <td>0.729700</td>\n      <td>0.710500</td>\n      <td>1.508475e+09</td>\n      <td>81.000000</td>\n      <td>45.000000</td>\n      <td>9.267570e+05</td>\n      <td>84.000000</td>\n      <td>83.000000</td>\n      <td>91.000000</td>\n      <td>87.000000</td>\n      <td>84.000000</td>\n      <td>...</td>\n      <td>1.700900</td>\n      <td>0.058420</td>\n      <td>1.202000</td>\n      <td>1.122200</td>\n      <td>0.595700</td>\n      <td>0.323300</td>\n      <td>0.076388</td>\n      <td>2.535400</td>\n      <td>1.957400</td>\n      <td>1.530850</td>\n      <td>0.056469</td>\n      <td>3.361800</td>\n      <td>3.055100</td>\n      <td>-0.270300</td>\n      <td>1.0</td>\n      <td>-0.710000</td>\n      <td>-0.630000</td>\n      <td>-0.699000</td>\n      <td>-0.575900</td>\n      <td>-11.530000</td>\n      <td>5.000000</td>\n      <td>1.480000</td>\n      <td>-5.700000</td>\n      <td>0.740000</td>\n      <td>0.198400</td>\n      <td>-0.704275</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>19.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>52736.000000</td>\n      <td>129.000000</td>\n      <td>9.000000</td>\n      <td>0.498267</td>\n      <td>2200.000000</td>\n      <td>4.000000</td>\n      <td>76530.000000</td>\n      <td>2292.000000</td>\n      <td>1786.000000</td>\n      <td>128.460000</td>\n      <td>129.080000</td>\n      <td>11.000000</td>\n      <td>0.770500</td>\n      <td>0.754200</td>\n      <td>1.672764e+06</td>\n      <td>0.745800</td>\n      <td>0.736000</td>\n      <td>0.539200</td>\n      <td>0.761900</td>\n      <td>0.818200</td>\n      <td>0.798200</td>\n      <td>2.233947e+09</td>\n      <td>91.000000</td>\n      <td>65.000000</td>\n      <td>1.115136e+06</td>\n      <td>94.780000</td>\n      <td>94.000000</td>\n      <td>108.000000</td>\n      <td>99.000000</td>\n      <td>92.000000</td>\n      <td>...</td>\n      <td>4.261950</td>\n      <td>0.083637</td>\n      <td>3.081600</td>\n      <td>2.840700</td>\n      <td>1.627000</td>\n      <td>0.957600</td>\n      <td>0.103507</td>\n      <td>5.855800</td>\n      <td>4.711500</td>\n      <td>3.830000</td>\n      <td>0.082008</td>\n      <td>7.564900</td>\n      <td>7.045500</td>\n      <td>-0.181800</td>\n      <td>1.0</td>\n      <td>-0.500000</td>\n      <td>-0.480000</td>\n      <td>-0.480000</td>\n      <td>-0.503100</td>\n      <td>-5.440000</td>\n      <td>11.000000</td>\n      <td>3.570000</td>\n      <td>-2.600000</td>\n      <td>1.990000</td>\n      <td>0.251800</td>\n      <td>0.375400</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>40.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>79103.500000</td>\n      <td>148.000000</td>\n      <td>9.000000</td>\n      <td>0.749494</td>\n      <td>3700.000000</td>\n      <td>10.000000</td>\n      <td>80135.000000</td>\n      <td>4679.000000</td>\n      <td>3411.000000</td>\n      <td>149.080000</td>\n      <td>148.310000</td>\n      <td>13.000000</td>\n      <td>0.831900</td>\n      <td>0.815100</td>\n      <td>4.731222e+06</td>\n      <td>0.804900</td>\n      <td>0.796700</td>\n      <td>0.627000</td>\n      <td>0.823000</td>\n      <td>0.876100</td>\n      <td>0.855900</td>\n      <td>4.031443e+09</td>\n      <td>98.000000</td>\n      <td>84.000000</td>\n      <td>1.293732e+06</td>\n      <td>104.000000</td>\n      <td>101.000000</td>\n      <td>128.750000</td>\n      <td>109.890000</td>\n      <td>99.000000</td>\n      <td>...</td>\n      <td>10.210900</td>\n      <td>0.217172</td>\n      <td>7.569000</td>\n      <td>6.859100</td>\n      <td>4.152300</td>\n      <td>2.595800</td>\n      <td>0.156381</td>\n      <td>13.316650</td>\n      <td>10.987400</td>\n      <td>9.148000</td>\n      <td>0.219453</td>\n      <td>16.463500</td>\n      <td>15.448100</td>\n      <td>-0.123900</td>\n      <td>1.0</td>\n      <td>-0.230000</td>\n      <td>-0.330000</td>\n      <td>-0.248000</td>\n      <td>-0.420000</td>\n      <td>-2.390000</td>\n      <td>23.000000</td>\n      <td>7.700000</td>\n      <td>-1.010000</td>\n      <td>4.440000</td>\n      <td>0.283600</td>\n      <td>0.737100</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>104.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>105471.000000</td>\n      <td>176.000000</td>\n      <td>11.000000</td>\n      <td>0.999994</td>\n      <td>7900.000000</td>\n      <td>17.000000</td>\n      <td>88565.000000</td>\n      <td>9968.000000</td>\n      <td>11541.000000</td>\n      <td>172.950000</td>\n      <td>175.270000</td>\n      <td>40.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>7.037873e+07</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.563049e+10</td>\n      <td>126.000000</td>\n      <td>184.000000</td>\n      <td>2.603664e+06</td>\n      <td>218.730000</td>\n      <td>160.490000</td>\n      <td>220.630000</td>\n      <td>159.900000</td>\n      <td>126.000000</td>\n      <td>...</td>\n      <td>91.821900</td>\n      <td>0.500000</td>\n      <td>77.673100</td>\n      <td>68.652100</td>\n      <td>48.579400</td>\n      <td>36.473500</td>\n      <td>0.497640</td>\n      <td>112.770300</td>\n      <td>95.343600</td>\n      <td>82.293100</td>\n      <td>0.500000</td>\n      <td>127.346800</td>\n      <td>120.425000</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>168.000000</td>\n      <td>58.120000</td>\n      <td>0.000000</td>\n      <td>34.040000</td>\n      <td>0.473700</td>\n      <td>11.092000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1212.000000</td>\n      <td>100.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 752 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "031a49103636eaa5dc31f4b6c2245aed1dfd19f1"
      },
      "cell_type": "code",
      "source": "# # Missing Values\n\n# Function to calculate missing values by column\ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6b9e205e77fa49de21972eb4884477ac0f8bc349",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "missing_values_table(data).head(50)",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Your selected dataframe has 771 columns.\nThere are 525 columns that have missing values.\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "      Missing Values  % of Total Values\nf662           18833               17.9\nf663           18833               17.9\nf159           18736               17.8\nf160           18736               17.8\nf170           18417               17.5\nf169           18417               17.5\nf618           18407               17.5\nf619           18407               17.5\nf331           18067               17.1\nf330           18067               17.1\nf179           17162               16.3\nf180           17162               16.3\nf422           14235               13.5\nf653           13205               12.5\nf190           12234               11.6\nf189           12234               11.6\nf340           11911               11.3\nf341           11911               11.3\nf726           11282               10.7\nf665           11282               10.7\nf669           11282               10.7\nf668           11282               10.7\nf664           11282               10.7\nf667           11282               10.7\nf666           11282               10.7\nf640            9700                9.2\nf199            9068                8.6\nf200            9068                8.6\nf650            9003                8.5\nf651            9003                8.5\nf72             9002                8.5\nf586            8965                8.5\nf587            8965                8.5\nf649            8716                8.3\nf648            8657                8.2\nf588            8432                8.0\nf621            8180                7.8\nf620            8180                7.8\nf673            7343                7.0\nf672            7343                7.0\nf210            6861                6.5\nf209            6861                6.5\nf679            6393                6.1\nf149            2859                2.7\nf150            2859                2.7\nf32             2572                2.4\nf152            2561                2.4\nf151            2561                2.4\nf171            2561                2.4\nf181            2561                2.4",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Missing Values</th>\n      <th>% of Total Values</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>f662</th>\n      <td>18833</td>\n      <td>17.9</td>\n    </tr>\n    <tr>\n      <th>f663</th>\n      <td>18833</td>\n      <td>17.9</td>\n    </tr>\n    <tr>\n      <th>f159</th>\n      <td>18736</td>\n      <td>17.8</td>\n    </tr>\n    <tr>\n      <th>f160</th>\n      <td>18736</td>\n      <td>17.8</td>\n    </tr>\n    <tr>\n      <th>f170</th>\n      <td>18417</td>\n      <td>17.5</td>\n    </tr>\n    <tr>\n      <th>f169</th>\n      <td>18417</td>\n      <td>17.5</td>\n    </tr>\n    <tr>\n      <th>f618</th>\n      <td>18407</td>\n      <td>17.5</td>\n    </tr>\n    <tr>\n      <th>f619</th>\n      <td>18407</td>\n      <td>17.5</td>\n    </tr>\n    <tr>\n      <th>f331</th>\n      <td>18067</td>\n      <td>17.1</td>\n    </tr>\n    <tr>\n      <th>f330</th>\n      <td>18067</td>\n      <td>17.1</td>\n    </tr>\n    <tr>\n      <th>f179</th>\n      <td>17162</td>\n      <td>16.3</td>\n    </tr>\n    <tr>\n      <th>f180</th>\n      <td>17162</td>\n      <td>16.3</td>\n    </tr>\n    <tr>\n      <th>f422</th>\n      <td>14235</td>\n      <td>13.5</td>\n    </tr>\n    <tr>\n      <th>f653</th>\n      <td>13205</td>\n      <td>12.5</td>\n    </tr>\n    <tr>\n      <th>f190</th>\n      <td>12234</td>\n      <td>11.6</td>\n    </tr>\n    <tr>\n      <th>f189</th>\n      <td>12234</td>\n      <td>11.6</td>\n    </tr>\n    <tr>\n      <th>f340</th>\n      <td>11911</td>\n      <td>11.3</td>\n    </tr>\n    <tr>\n      <th>f341</th>\n      <td>11911</td>\n      <td>11.3</td>\n    </tr>\n    <tr>\n      <th>f726</th>\n      <td>11282</td>\n      <td>10.7</td>\n    </tr>\n    <tr>\n      <th>f665</th>\n      <td>11282</td>\n      <td>10.7</td>\n    </tr>\n    <tr>\n      <th>f669</th>\n      <td>11282</td>\n      <td>10.7</td>\n    </tr>\n    <tr>\n      <th>f668</th>\n      <td>11282</td>\n      <td>10.7</td>\n    </tr>\n    <tr>\n      <th>f664</th>\n      <td>11282</td>\n      <td>10.7</td>\n    </tr>\n    <tr>\n      <th>f667</th>\n      <td>11282</td>\n      <td>10.7</td>\n    </tr>\n    <tr>\n      <th>f666</th>\n      <td>11282</td>\n      <td>10.7</td>\n    </tr>\n    <tr>\n      <th>f640</th>\n      <td>9700</td>\n      <td>9.2</td>\n    </tr>\n    <tr>\n      <th>f199</th>\n      <td>9068</td>\n      <td>8.6</td>\n    </tr>\n    <tr>\n      <th>f200</th>\n      <td>9068</td>\n      <td>8.6</td>\n    </tr>\n    <tr>\n      <th>f650</th>\n      <td>9003</td>\n      <td>8.5</td>\n    </tr>\n    <tr>\n      <th>f651</th>\n      <td>9003</td>\n      <td>8.5</td>\n    </tr>\n    <tr>\n      <th>f72</th>\n      <td>9002</td>\n      <td>8.5</td>\n    </tr>\n    <tr>\n      <th>f586</th>\n      <td>8965</td>\n      <td>8.5</td>\n    </tr>\n    <tr>\n      <th>f587</th>\n      <td>8965</td>\n      <td>8.5</td>\n    </tr>\n    <tr>\n      <th>f649</th>\n      <td>8716</td>\n      <td>8.3</td>\n    </tr>\n    <tr>\n      <th>f648</th>\n      <td>8657</td>\n      <td>8.2</td>\n    </tr>\n    <tr>\n      <th>f588</th>\n      <td>8432</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>f621</th>\n      <td>8180</td>\n      <td>7.8</td>\n    </tr>\n    <tr>\n      <th>f620</th>\n      <td>8180</td>\n      <td>7.8</td>\n    </tr>\n    <tr>\n      <th>f673</th>\n      <td>7343</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>f672</th>\n      <td>7343</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>f210</th>\n      <td>6861</td>\n      <td>6.5</td>\n    </tr>\n    <tr>\n      <th>f209</th>\n      <td>6861</td>\n      <td>6.5</td>\n    </tr>\n    <tr>\n      <th>f679</th>\n      <td>6393</td>\n      <td>6.1</td>\n    </tr>\n    <tr>\n      <th>f149</th>\n      <td>2859</td>\n      <td>2.7</td>\n    </tr>\n    <tr>\n      <th>f150</th>\n      <td>2859</td>\n      <td>2.7</td>\n    </tr>\n    <tr>\n      <th>f32</th>\n      <td>2572</td>\n      <td>2.4</td>\n    </tr>\n    <tr>\n      <th>f152</th>\n      <td>2561</td>\n      <td>2.4</td>\n    </tr>\n    <tr>\n      <th>f151</th>\n      <td>2561</td>\n      <td>2.4</td>\n    </tr>\n    <tr>\n      <th>f171</th>\n      <td>2561</td>\n      <td>2.4</td>\n    </tr>\n    <tr>\n      <th>f181</th>\n      <td>2561</td>\n      <td>2.4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c14e564d273adf7a71072ca75e1906e8e3d3b0a6"
      },
      "cell_type": "code",
      "source": "data.fillna(data.mean(), inplace=True)",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ee7b2b30918685d90ad4b3062e205c7c81172ee3"
      },
      "cell_type": "code",
      "source": "missing_values_table(data).head(50)",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Your selected dataframe has 771 columns.\nThere are 12 columns that have missing values.\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "      Missing Values  % of Total Values\nf206            1291                1.2\nf207            1291                1.2\nf390             698                0.7\nf391             698                0.7\nf626             698                0.7\nf627             698                0.7\nf695             698                0.7\nf698             698                0.7\nf138             182                0.2\nf137             177                0.2\nf276             101                0.1\nf277             101                0.1",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Missing Values</th>\n      <th>% of Total Values</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>f206</th>\n      <td>1291</td>\n      <td>1.2</td>\n    </tr>\n    <tr>\n      <th>f207</th>\n      <td>1291</td>\n      <td>1.2</td>\n    </tr>\n    <tr>\n      <th>f390</th>\n      <td>698</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>f391</th>\n      <td>698</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>f626</th>\n      <td>698</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>f627</th>\n      <td>698</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>f695</th>\n      <td>698</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>f698</th>\n      <td>698</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>f138</th>\n      <td>182</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>f137</th>\n      <td>177</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>f276</th>\n      <td>101</td>\n      <td>0.1</td>\n    </tr>\n    <tr>\n      <th>f277</th>\n      <td>101</td>\n      <td>0.1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1a9d4567ec2eaa47b63110c90df17d6e38aeee87"
      },
      "cell_type": "code",
      "source": "data.dropna(inplace=True)\nmissing_values_table(data)",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Your selected dataframe has 771 columns.\nThere are 0 columns that have missing values.\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "Empty DataFrame\nColumns: [Missing Values, % of Total Values]\nIndex: []",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Missing Values</th>\n      <th>% of Total Values</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2db9645d013be1732179ef0f682a2268c24df15d"
      },
      "cell_type": "code",
      "source": "data.shape",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "(103302, 771)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d04cdc680bc805aeabaf6afcbc7d1f6c03e0e7d3"
      },
      "cell_type": "code",
      "source": "# # # Exploratory Data Analysis\n\nfor i in data.select_dtypes(include=['object']).columns:\n    data.drop(labels=i, axis=1, inplace=True)",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "90cc9e82a25bd463d7a6c477cfdc8e4680eaf1b8"
      },
      "cell_type": "code",
      "source": "# # Single Variable Plots\n\nfigsize=(8, 8)\n\n# Histogram of the loss\nplt.style.use('fivethirtyeight')\nplt.hist(data['loss'], bins = 100, edgecolor = 'k')\nplt.xlabel('Loss') \nplt.ylabel('Number of Clients');\nplt.title('Loss Distribution')",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "Text(0.5,1,'Loss Distribution')"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAE6CAYAAADZUxEVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzs3XlYlWUe//H3ERBEMBUFFRU1FzTIRLTSlMp1fmY2w2RaKpliU5lOVpq/yqVsxKiZaQLU3Bn1MoPGcSkdt7BcCoURCVBcUtwgIUVQkO33h79zhuM54MEOSvJ5XVfXBc99f5/nyy2dL/ez3I/h4sWLZYiIiEiNVOdOJyAiIiIVU6EWERGpwVSoRUREajAVahERkRpMhVpERKQGU6EWERGpwVSoRcQuPvvsM3r27MmBAwfuyPEPHDhAz549+eyzz8y2/+lPf6Jnz56cPXv2juQFcPbsWXr27Mns2bPvWA7y2+V4pxMQ+a3r2bMnAD/88MMdzuTXM/4sRo6OjtSvX5+mTZvSsWNHgoKC6NOnD46O9v/omD17Nps2bWL+/Pl0797d7vuvTmfPnuWpp54iICCABQsW3Ol05C6jQi0iFsaPHw9AaWkpeXl5nDx5ku3bt/PVV1/h4+PD7Nmz6dKli1nM8OHDGThwIM2aNbsTKXPfffexdu1aGjZseEeOXxlPT0/Wrl2Lm5vbnU5FfoNUqEXEwoQJEyy25ebmMn/+fGJjY3n11VdZunQpPj4+pvaGDRve0SLp4uJCmzZt7tjxK+Po6Fhjc5OaT4Va5DY7cuQIy5YtIzExkdzcXBo3bsyDDz7ICy+8gLe3t1nf/Px81qxZw7Zt2zh//jylpaU0bNiQTp068cwzz5idIk5MTGTlypUcPnyYX375BTc3N7y8vAgICGDy5MkYDIZflXeDBg2YNm0a+fn5bN68mYiICMLDw03tn332GYsXL7Y4dW1LXsOGDePcuXMAvPTSS2bHNV5SKH9qPDMzk88//5wTJ07QqlUrVq1axYEDB3jppZcYP3681T80ysrKWLlyJevWreP8+fM0bNiQ/v37ExoaSv369c369uzZs8LT2Df+nBs3buS9994DICEhwezygTEX46nxIUOGMHPmTLP9ZWdns2zZMr777jt+/vln6tWrh7+/P6NHjyYgIMCsr/FnHDJkCKGhoURGRvLDDz9w9epV2rVrR2hoKH369Kn4H1F+k1SoRW6jPXv2MHXqVEpKSnjsscdo2bIl6enpbNiwgbi4OKKioujYsSNwvbBMnjyZpKQk7rvvPoYOHYqTkxM///wz//3vf/nhhx9MBXHv3r289tpruLq60qdPH7y8vMjNzSUjI4PPP/+ciRMn2u268oQJE9i8eTPfffcdeXl5lZ7OtTWvESNGsHHjRtLT0xkyZAjNmzevcJ8rV65k//799OnThx49elBUVGRT3n/96185ePAg/fr1w83Njb1797J69WoOHjzIwoULqVu3bpXHAqBjx46MGDGCNWvW0Lx5c4YMGWJqu9m19nPnzhEaGkpWVhYBAQEMGDCACxcusG3bNvbu3cs777zDE088YRF3/vx5xo4di7e3N7/73e/Izc1l27ZtvPnmm0RERBAYGHhLP4vUTCrUIrfJ1atXmTVrFsXFxRYfpv/+97/54IMPmDlzJqtXr8ZgMHDs2DGSkpLo27cvH330kdm+ysrKuHTpkun7devWUVpayoIFC0yF3ujixYt2vfmrZcuWeHp6kpWVRVpaWqVFwda8Ro4cyZEjR0hPT+eJJ56otMAdOHCAJUuWWOzvZpKSkli5cqXpGvrLL7/MtGnT2LVrF6tXr+b555+v0v6MbizU1mbzFQkLCyMrK4vQ0FBCQ0NN25977jnGjh1LWFgYPXr0wMvLyyzuwIEDFjGDBg1i8uTJrFy5UoX6LqPHs0Ruk7i4OC5evMhjjz1m8UE6bNgwfH19OXbsGIcOHTJrc3FxsdiXwWCwej3Y2dnZYlt1XDf29PQE4JdffrGpvz3zeuqpp6pcpAFGjBhhdqObg4MDr776KgaDgQ0bNtxSLr9GVlYWe/fuxdPT0+KPhPbt2xMcHMy1a9f4+uuvLWKbN2/OCy+8YLbt4YcfplmzZvz444/VmbbcASrUIrdJWloaQIWznR49egBw+PBhANq2bUvHjh35z3/+wwsvvMCKFStITEyksLDQInbw4MEAjB07lr/85S9s2bKlWp8bLiu7/nbcm133ro687rvvvluK69atm8U2Hx8fGjduTEZGBvn5+b8qr6oy/jt37doVJycni3bjtW7j7015HTp0wMHBwWK7l5cXly9ftnOmcqfp1LfIbZKXlweAh4eH1fYmTZoAmD5oHRwciIqKYunSpezcuZPIyEjg+gx7wIABvPrqq6ZZ6WOPPcbf/vY3Vq9ezaZNm1i3bh0A9957L6GhoTz++ON2/Vl+/vlnABo3blxpv+rIq6Lxu9W4xo0bk52dTX5+vsVNZdXJ1t8HY7/y3N3drcY4ODhQWlpqpwylplChFrlNjDddZWdnW22/cOGCWT+4fqf1n//8Z/785z9z5swZEhMT2bBhAxs2bODs2bPMnz/f1Ld379707t2bgoICUlJS2Lt3LzExMUyfPp358+db3EF8q06dOkVWVhYODg74+vretL+987rVu9ezs7PNHiczysnJATAr0gaDgZKSEqv7sVY4b8Wt/D5I7aRT3yK3ibGoVbTE5v79+8363cjb25snnniCyMhIvLy8OHDggNWi4eLiQkBAAK+88gqTJk2irKyMb775xj4/BLB48WIAgoKCcHV1tTnuZnnVqXP946iiAvlrJSYmWmw7efIkOTk5tGrVyqxQu7u7k5mZaXU/KSkpFtuMp6GrkrvxOvvBgwet3rkeHx8PVPz7ILWHCrXIbRIUFMQ999zDjh07SEhIMGvbuHEjqamptGvXDn9/fwDOnDnDmTNnLPZz5coVrl69iqOjo6lAJCQkUFxcbNHXOFuzdkNaVV2+fJl58+axefNmGjRowCuvvHLTmKrkdc899wBUWCB/rTVr1nD+/HnT9yUlJXz66aeUlZVZPALl5+fH+fPn2b17t9n2devWkZSUZLFvd3d3DAYDWVlZNufj5eXFQw89RFZWFtHR0WZtx44dIzY2lrp16/K73/3O5n3K3UmnvkXspLIXLkyePJmGDRsyY8YM3nrrLSZOnMjjjz9OixYtOHr0KLt378bd3Z1Zs2aZTu2mp6czbdo0fH19adu2LU2bNiU3N5fdu3eTm5vLc889R7169QD4+OOPyczM5IEHHqB58+bUrVuXo0ePsm/fPu655x5+//vfV+lnMb7YoqysjLy8PH766Sf++9//UlhYSNu2bZk9ezatWrW66X6qkteDDz7IypUriYyM5NixY6brsOPGjatS7hW5//77GTVqlNlz1EePHqVLly4899xzZn1HjRrFvn37mDp1Kv3796dRo0akpaWRmprKI488wnfffWfW39XVFX9/f5KSkpgyZQq+vr44ODjQrVu3Sk/tv/XWW4SGhrJw4UL279+Pv7+/6Tnqa9euMX36dItHs6T2UaEWsZNNmzZV2BYaGkrDhg3p06cPS5YsYfny5cTHx5tWJhsyZAjjxo0zW5msc+fOhISEkJCQwPfff09ubi733HMPbdq04c9//jP9+/c39X3++eeJi4sjNTXVdArd09OTESNG8Oyzz1b5w954etvR0RFXV1c8PT3p169flV/KUZW8HnzwQV5//XW+/PJLYmJiuHbtGmC/Qj1lyhR27NjBv//9b86dO0ejRo0YOXIkEyZMsFjsJDAwkI8++oglS5awY8cOnJyc6NatG0uXLmX79u0WhRqu/6H297//nf/+97/s2bOH0tJSxo8fX2mhbtGiBStWrDCtTHbw4EFcXV0JCAhg9OjRv7mXk0j1MFy8eLHsTichIiIi1ukatYiISA2mQi0iIlKDqVCLiIjUYCrUIiIiNZgKtYiISA2mQi0iIlKDqVCLiIjUYCrUd7n09PQ7ncJdSeNqfxrT6qFxtb/bPaYq1CIiIjWYCrWIiEgNpkItIiJSg6lQi4iI1GAq1CIiIjWYCrWIiEgNpkItIiJSg6lQi4iI1GCOdzoBqV6frIzlQomT6ft7G7vywZSX7mBGIiJSFSrUd7mMy8XE+Y82fT/42Jo7mI2IiFSVTn2LiIjUYCrUIiIiNZgKtYiISA2mQi0iIlKDqVCLiIjUYCrUIiIiNZgKtYiISA2mQi0iIlKDqVCLiIjUYCrUIiIiNZgKtYiISA2mQi0iIlKDqVCLiIjUYCrUIiIiNZgKtYiISA2mQi0iIlKDqVCLiIjUYCrUIiIiNZgKtYiISA2mQi0iIlKDqVCLiIjUYCrUIiIiNZgKtYiISA3meKcTAMjMzCQ6Oprvv/+ezMxMysrK8PLyIjAwkDFjxuDt7W01bvPmzcTGxnL06FFKS0vx8fFh6NChBAcHU6dOxX+D7N27l9WrV5OamkphYSHe3t4MHDiQUaNGUbdu3QrjkpOTWbFiBUlJSeTn5+Pl5UVQUBAvvPACbm5uFcadPHmSJUuWsH//fi5duoSHhwe9evVi/PjxNGnSxPaBEhGRWueOz6gPHz7Ms88+yxdffEFBQQEPPvggDz30EIWFhfzrX//iueeeIykpySLuww8/ZMaMGaSlpfHAAw/Qs2dPMjIyCA8P56233qK0tNTq8aKjo5k8eTL79++nU6dO9O7dm19++YUFCxbwpz/9iYKCAqtxW7ZsITQ0lLi4OFq3bk3fvn0pKipi5cqVhISEkJOTYzUuISGBUaNGsXnzZpo0acKjjz6Ki4sLX375Jc899xwnT5689cETEZG73h2fUX/44YdcvnyZp556iqlTp+LoeD2l4uJi5s6dy4YNGwgLC2P16tWmmB07dhATE4OHhwcLFy6kdevWAGRnZ/Pyyy/zzTffsHbtWkaMGGF2rJSUFCIjI3FxcSEqKgo/Pz8Arly5wmuvvUZiYiJRUVFMmTLFLC4zM5M5c+ZQVlZGeHg4QUFBphxnzpzJ1q1bmTt3LuHh4WZxV69e5e2336awsJA33niD4cOHm9o++eQTVq1axbvvvsuKFSswGAx2GlEREbmb3NEZdWFhIYcOHQJgwoQJpiIN4OjoyEsvvQTA0aNHzWa6y5cvB2DixImmIg3g4eHBtGnTAFixYoXFrDo6OpqysjLGjBljKtIArq6uzJgxgzp16hAbG8vly5fN4tasWUNhYSFDhgwxFWljjtOnT6d+/frExcVx/Phxs7gNGzaQnZ1N9+7dzYq0MfeWLVuSlpbGnj17bBswERGpde5ooXZwcMDBweGm/erVq4ezszNwfXablpaGk5MT/fr1s+gbEBCAp6cn2dnZJCcnm7YXFRWZCuLgwYMt4ry9vfH396eoqIjdu3ebtcXFxQEwaNAgizg3Nzf69Olj1u/GOGvHc3BwYMCAAVbjREREjO5ooXZ0dKRHjx4AfPbZZxQXF5vaiouLWbBgAQBPPvmk6dTwkSNHAGjXrh0uLi5W99u5c2fg+vVvo5MnT1JQUECDBg1o2bJlpXHGYwDk5eVx+vRpALp06WI1zri9/PHKf1/VOBEREaNfdY362rVr7Ny5k8uXL9OnTx+8vLyqvI9p06YxadIk1q1bx549e0zFMjU1ldzcXEaMGMGkSZNM/c+ePQtAs2bNKtynsc3Y99fEnTt3DgB3d/cK7+w2/tzl4/Ly8sjNzQWgefPmNh9PRESkPJsLdXh4OIcOHSI6OhqAkpISJkyYQFpaGmVlZURGRrJo0SLat29fpQS8vb1ZsmQJs2bNYs+ePWRlZZnaOnfuTLdu3cyuXV+5cgW4fjq8IsY2Y19b41xdXQHIz883bbt69arNceWPZ4wDKpz5W8tTRESkPJsL9d69e+nfv7/p+23btpGamsrUqVPp1KkT7777LkuWLGHu3LlVSiApKYmpU6dSv359PvroI+6//34ADh48yCeffMK0adOYMGEC48ePr9J+7ybp6el229fVK1ftur/aTONofxrT6qFxtb9fM6YdOnSoUn+bC/WFCxfMFh6Ji4ujQ4cOBAcHA/CHP/yBzz//vEoHv3z5Mm+++SZXr15lyZIlZvsPCgqiXbt2PPvssyxZsoSBAwfSunVr0+y1/Iz1RsY2Y9/yX1cWZ5zZ1q9f37TNOOu1Ja788crPwAsKCqyeNreWpzVV/UetTD3XenbdX22Vnp6ucbQzjWn10Lja3+0eU5tvJqtbt67pEamysjL279/PQw89ZGp3d3fn0qVLVTr47t27+eWXX/Dz87O6+lirVq3w8/OjpKSEhIQE4H/Xe8+fP1/hfjMzM8362iPu8uXL5OXlWY0znq5v0aKFaZubmxsNGjQA/ned25bjiYiIlGdzob733nvZvHkzubm5rF+/ntzcXHr16mVqP3fuHA0bNqzSwY1Fs7LlN41txj8COnXqBMDx48crXEUsJSXFrC9AmzZtcHZ2Jjc313QXty1xbm5uprvEje03+vHHHwHo2LGj2Xbjfm4WV/54IiIi5dlcqMeNG8fRo0cZOHAgc+fOpWvXrgQEBJjad+/ezX333VelgxvXuU5LSzN7NMuouLiYtLQ04H+zVS8vL3x9fSkqKmL79u0WMQkJCWRlZeHh4YG/v79pu5OTk+kPi82bN1vEnTlzhkOHDuHk5ETv3r3N2vr27QtcX0b0Rnl5eXz77bcAPProo1bjrB2vpKSErVu3Wo0TERExsrlQ9+zZk+joaF577TXeeecd/vGPf5jaLl26REBAAE8//XSVDt6rVy9cXFw4f/48f/vb37h27Zqp7dq1a3z00UdkZmbSoEEDHn74YVNbSEgIABEREWRkZJi25+TkMG/ePFOfG1/MERISgsFgIDo62jSbhevXmN9//31KS0sJDg7G3d3dLG7kyJE4OzuzadMmdu3aZdpeXFxMWFgY+fn5pmvq5Q0dOhQPDw8OHDjAF198YdYWGRnJ6dOn6dSpk9mZCRERkfIMFy9eLLOl4/nz52nYsGGFjxoVFBRw8eLFSp9Ttmbjxo188MEHlJSU0LRpU9Np4LS0NC5cuEDdunWZM2eOxaxz3rx5xMbG4uzsTI8ePXB0dCQ+Pt5UNMPCwqyuehYdHU1ERAQODg4EBgbi5uZGYmIiOTk5+Pn5ERUVZfVn3LJlC7NmzaK0tJSuXbvStGlTkpOTOXfuHK1atWLRokU0btzYIi4hIYHJkydTWFiIr68vrVu3Jj09nRMnTtCwYUMWLVqEj49PlcasKoZNmUOc/1jT94OPrWHNnNer7Xi1hW7QsT+NafXQuNrf7R5Th7feemuWLR379+9PmzZtKnxOeufOnbz44otVfoyqY8eOPPLIIxQUFJCVlcXRo0c5c+YMDRo04LHHHmPGjBl069bNIu6RRx6hVatWZGVlkZKSQkZGBj4+PowdO5ZJkyZVuDRp165d8fPz48KFC6SmpnLixAmaNm3KiBEj+L//9/+aliq9Ufv27XnooYf45ZdfOHz4MOnp6bi7u/Pkk0/y3nvvcc8991iNa968Of369SM3N5f09HQOHz6Mo6MjAwcO5C9/+YvZDWjVYc2WXZz0+t/4tf8lmT8+rhn8r5WTk4OHh8edTuOuojGtHhpX+7vdY2rz41llZZVPvEtKSm75DVC+vr7Mnj27ynGDBw+2uo72zTz88MNmp9Jt5efnx0cffVTlOB8fH95///0qx4mIiFRpre+KCnFeXh579uyhUaNGdklKRERErqt0Rr1o0SKWLFkCXC/SM2fOZObMmVb7lpWVMXLkSPtnKCIiUotVWqjvu+8+08pjMTEx9OzZ0+z9z3C9gNerV4/OnTvz2GOPVV+mIiIitVClhbpXr16mR4euXr3KH/7wB/z8/G5LYiIiIlKFm8lmzJhRnXmIiIiIFVV6H3VJSQn79u3jzJkzXL582eJOcIPBwLhx4+yaoIiISG1mc6FOSUnhrbfeIisrq8JHtVSoRURE7MvmQv3hhx9SWFhIeHg4DzzwgMUymyIiImJ/Nhfqo0eP8tJLL9GnT5/qzEdERETKsXnBE09Pz5uuTiYiIiL2ZXOhHjNmDOvWrSMvL6868xEREZFybD71nZubS7169QgODubxxx/Hy8vL4jWSBoOB0aNH2z1JERGR2srmQh0ZGWn6+ssvv7TaR4VaRETEvmwu1OvWravOPERERMQKmwt18+bNqzMPERERsaJKK5MBnDp1ioSEBHJychg8eDAtWrSgqKiI7OxsPDw8cHJyqo48RUREaiWbC3VpaSlhYWGsX7+esrIyDAYD/v7+pkI9cuRIxo8fz3PPPVed+YqIiNQqNj+etWzZMjZs2MCLL77IkiVLzJ6pdnV15fHHH2fnzp3VkqSIiEhtZXOh3rhxI0OHDmXs2LG0bNnSov3ee+8lIyPDrsmJiIjUdjYX6qysLLp06VJhu7OzM1euXLFLUiIiInKdzYXaw8OD8+fPV9ielpZGs2bN7JKUiIiIXGdzoX7ssceIjY3l1KlTpm0GgwGAPXv28NVXX9G/f3/7ZygiIlKL2XzXd2hoKAkJCYwePZquXbtiMBhYvnw5UVFRpKSk4OvrS0hISHXmKiIiUuvYPKN2c3Nj8eLFPP/88+Tk5FC3bl0OHjzIlStXCA0NZeHChbi4uFRnriIiIrVOlRY8cXZ2ZuzYsYwdO7a68hEREZFybJ5Ri4iIyO1X4Yx68eLFGAwGxo4dS506dVi8ePFNd2YwGBg3bpxdExQREanNKizUixYtwmAwMGbMGOrUqcOiRYtuujMVahEREfuqsFB///33lX4vIiIi1U/XqEVERGqwKr/msroUFBSwdu1atm/fTkZGBkVFRTRu3JjOnTszcuRIunbtata/tLSU2NhYNmzYwMmTJ6lTpw7t27fnj3/8I4MGDar0WJs3byY2NpajR49SWlqKj48PQ4cOJTg4mDp1Kv7bZe/evaxevZrU1FQKCwvx9vZm4MCBjBo1irp161YYl5yczIoVK0hKSiI/Px8vLy+CgoJ44YUXcHNzq9pAiYhIrVJhoX7ppZeqvDODwUBUVFSV486cOcOkSZPIyMigSZMmdO/eHQcHB86fP09cXBwdOnQwK9QlJSVMmzaNXbt2Ub9+fR588EGKioqIj4/n3XffJTk5mddff93qsT788ENiYmJwdnYmMDAQR0dH9u/fT3h4OPHx8YSFhVkt1tHR0URERODg4EBAQADu7u4kJiayYMECvvvuO6Kioqw+R75lyxZmzZpFSUkJXbt2pWnTpiQnJ7Ny5Uri4uJYtGgRjRs3rvKYiYhI7VBhoTa+c7oqyr/60lZXr17l1Vdf5cyZM7zyyiuMGjUKBwcHU/vFixe5dOmSWcyaNWvYtWsXbdu2JSoqCg8PDwBOnTrFhAkT+PzzzwkMDCQoKMgsbseOHcTExODh4cHChQtp3bo1ANnZ2bz88st88803rF27lhEjRpjFpaSkEBkZiYuLC1FRUfj5+QFw5coVXnvtNRITE4mKimLKlClmcZmZmcyZM4eysjLCw8NN+RQXFzNz5ky2bt3K3LlzCQ8Pr/K4iYhI7VBhoV6wYMFtSWDp0qWcPn2ap59+2uoSpA0bNqRhw4am70tKSvjnP/8JwLRp00xFGqB169ZMnDiR9957j2XLllkU6uXLlwMwceJEU5GG6y8cmTZtGn/6059YsWIFw4cPN5tVR0dHU1ZWxpgxY0xFGq6/h3vGjBkEBwcTGxtLaGgo7u7upvY1a9ZQWFjI0KFDzXJxdHRk+vTp7Nmzh7i4OI4fP067du2qOnQiIlIL3NGbyYqKili3bh0Azz77rE0xhw4dIicnB09PTwICAiza+/fvj6OjIykpKWRlZZm2Z2ZmkpaWhpOTE/369bOICwgIwNPTk+zsbJKTk81y3LNnDwCDBw+2iPP29sbf35+ioiJ2795t1hYXFwdg9Zq5m5sbffr0MesnIiJyo0oLdV5eHpMmTWLZsmWV7mTp0qVMnjy5yu+jTk1N5dKlS3h6euLt7U1aWhoLFixg7ty5LFy4kP/+978WMYcPHwao8N3YLi4uptnpkSNHTNuNX7dr167CNck7d+5sdgyAkydPUlBQQIMGDWjZsmWlceWPl5eXx+nTpyvN1bi9/PFERETKq7RQf/HFFxw6dIhhw4ZVupNhw4aRlJREbGxslQ5+7NgxAJo2bconn3zCmDFjWLp0Kf/6179YsmQJEyZM4M033+Tq1aummLNnzwJU+u5rY5ux752IO3fuHADu7u4V3tnt5eVlESciIlJepYU6Li6Ofv363fSuZA8PDwYMGMCOHTuqdPDc3Fzg+oxy1apVjBgxgi+//JLt27fz0Ucf4enpSVxcHPPmzTPFGIt2vXr1Ktyvsa38DN/4dXXEubq6ApCfn1+lPI1xVT0TISIitUelz1H/9NNPDB061KYdderUia1bt1bp4KWlpcD1u6B/97vfmd013bdvX5o0acLYsWP5+uuvGT9+fIWnnu926enpdtvX1StX7bq/2kzjaH8a0+qhcbW/XzOmHTp0qFL/Sgt1SUmJ2aNSlXFwcKC4uLhKBzfOKAGrp9e7dOmCr68vqampJCQk0LJlS9MMtfzp8BsZ28rv3/h1dcQZZ8T169c3bbMlT2Nc+eNZU9V/1MrUc61n1/3VVunp6RpHO9OYVg+Nq/3d7jGt9NS3p6cnR48etWlHR48exdPTs0oHb9Gihelrb2/vSvtkZ2ebfX/+/PkK95uZmQlA8+bNTduMX9/uuMuXL5OXl2c1znhXevlxEBERKa/SQv3QQw/x9ddfc+HChUp3cuHCBb7++mseeuihKh28U6dOpq9vXNTE6OLFi8D/Zp3GmJSUFKv9CwoKTDepld+/8evjx49TUFBgNda4z/Jxbdq0wdnZmdzcXNNd3LbEubm5mU7VV5Trjz/+CEDHjh2ttouIiFRaqEePHk1JSQmvvPIKSUlJVvskJSXxyiuvUFJSwqhRo6p0cE9PT9MCIvHx8Rbtubm5pkeXjI9A+fv706hRI7KyskhISLCI2bZtG8XFxXTp0sVshu/l5YWvry9FRUVs377dIi4hIYGsrCw8PDzw9/c3bXdycqJXr17A9TVZFv/BAAAgAElEQVTCb3TmzBkOHTqEk5MTvXv3Nmvr27cvcH0Z0Rvl5eXx7bffAvDoo49atIuIiMBNCnWzZs2YO3cuWVlZTJgwgT/84Q9MnTqVWbNmMXXqVIKDg5kwYQJZWVn85S9/MTv1a6uxY8cCsGzZMrOZZ2FhIfPmzSMvLw9fX19T8XRwcGD06NEAzJs3j5ycHFPMqVOniIyMNNtvecaVzyIiIsjIyDBtz8nJMd1ZHhISYrHWd0hICAaDgejoaNMsGK5fY37//fcpLS0lODjYbFUygJEjR+Ls7MymTZvYtWuXaXtxcTFhYWHk5+cTFBSkVclERKRChosXL950ge5z584RHR3Nt99+y88//2za3rRpU/r06cOoUaMqvMZsi08++YRVq1bh6OiIn58f99xzDykpKfz88894enoSFRVltuRnSUkJU6dO5dtvv6V+/fr06NGD4uJi4uPjKSwsZPjw4bzxxhtWjzVv3jxiY2NxdnamR48eODo6Eh8fbyqaYWFhVm+gK/9SjsDAQNzc3EhMTCQnJwc/P7+bvpSjtLTU7KUc586do1WrVtX+Uo5hU+YQ5/+/P1oGH1vDmjnWX1gittMNOvanMa0eGlf7u91jalOhLi8/P5/8/Hzq169vdpfzr7Vz507Wrl3LkSNHKCgooFmzZvTp04eQkBAaNWpk0b+0tJSYmBg2btzITz/9hIODA+3btyc4ONjqUp/lbd68mZiYGI4dO0ZJSQlt2rSx+TWXq1atIjU1lWvXrtGiRQsGDRpk02suly9fbvaay0cfffS2vOZShbp66MPP/jSm1UPjan81vlDLb4sKdfXQh5/9aUyrh8bV/mrU41kiIiJyZ6lQi4iI1GAq1CIiIjWYCrWIiEgNVmGhHj16NHv37jV9v2nTJr2OUURE5DarsFAfPXqUX375xfT9+++/X+HqZCIiIlI9KizUzZs3Z9++faY3PJWVlWEwGG5bYiIiIlLJay6HDx/O3/72N/7zn/8AYDAYmDlzJjNnzqxwZwaDwex0uYiIiPw6FRbqESNG0LlzZw4cOEBOTg4xMTH06NHDbClPERERqV4VFmqArl270rVrVwC++OILhgwZctPlOUVERMR+Ki3U5X3//ffVmYeIiIhYYXOhNtq9eze7d+/m3LlzwPWbzvr06cPDDz9s9+RERERqO5sLdWFhIW+99RZ79+7FYDDQpEkTAPbt28eXX37Jww8/zLx58yp9i5SIiIhUjc2F+rPPPmPPnj2MHz+ekSNHml7PmJ+fz5o1a1i0aBGLFi3ilVdeqbZkRUREahublxDdunUrQ4cOJTQ01OwdyvXr12fcuHE88cQTbNmypVqSFBERqa1sLtQ5OTl07ty5wnZfX19ycnLskpSIiIhcZ3Oh9vLyYv/+/RW279+/Hy8vL7skJSIiItfZXKiHDBnCjh07mDNnDseOHaO4uJji4mKOHTvGBx98wDfffMPQoUOrM1cREZFax+abyZ5//nnOnj3Lhg0b2Lhxo2nd77KyMsrKynjyyScJCQmptkRFRERqI5sLdZ06dXjnnXcYMWKExXPUvXv3pn379tWWpIiISG1V5QVP2rdvr6IsIiJym9h8jVpERERuPxVqERGRGkyFWkREpAZToRYREanBVKhFRERqMJsKdUFBAQ899BBLly6t7nxERESkHJsKtYuLCw0bNjR7GYeIiIhUP5tPfffv359t27ZRWlpanfmIiIhIOTYvePLoo4+yf/9+QkNDeeqpp/D29sbZ2dmi33333WfXBEVERGozmwv1K6+8Yvo6OTnZtNa3UVlZGQaDgX379tkvOxERkVrO5kL97rvvVmceJlFRUSxfvhyASZMmMWrUKKv9Nm/eTGxsLEePHqW0tBQfHx+GDh1KcHAwdepUfEZ/7969rF69mtTUVAoLC/H29mbgwIGMGjWKunXrVhiXnJzMihUrSEpKIj8/Hy8vL4KCgnjhhRcqvXZ/8uRJlixZwv79+7l06RIeHh706tWL8ePH06RJE9sGRUREai2bC/UTTzxRnXkAkJKSwj//+U8MBgNlZWUV9vvwww+JiYnB2dmZwMBAHB0d2b9/P+Hh4cTHxxMWFma1WEdHRxMREYGDgwMBAQG4u7uTmJjIggUL+O6774iKisLFxcUibsuWLcyaNYuSkhK6du1K06ZNSU5OZuXKlcTFxbFo0SIaN25sEZeQkMDkyZMpLCzE19eXbt26kZ6ezpdffsnOnTv57LPP8PHx+XWDJiIid7Uqv5QD4NSpU/zyyy/ce++9drsT/Nq1a8yePZvGjRvTpUsX4uLirPbbsWMHMTExeHh4sHDhQlq3bg1AdnY2L7/8Mt988w1r165lxIgRZnEpKSlERkbi4uJCVFQUfn5+AFy5coXXXnuNxMREoqKimDJlillcZmYmc+bMoaysjPDwcIKCggAoLi5m5syZbN26lblz5xIeHm4Wd/XqVd5++20KCwt54403GD58uKntk08+YdWqVbz77rusWLHC4jKCiIiIUZUWPNm8eTNDhw5l+PDhvPjii6SmpgJw8eJFgoOD2bp16y0nsnDhQk6cOMFbb71VafE3nhafOHGiqUgDeHh4MG3aNABWrFhhcXd6dHQ0ZWVljBkzxlSkAVxdXZkxYwZ16tQhNjaWy5cvm8WtWbOGwsJChgwZYirSAI6OjkyfPp369esTFxfH8ePHzeI2bNhAdnY23bt3NyvSxtxbtmxJWloae/bssWF0RESktrK5UO/YsYOZM2fSpk0bXn31VbNT0w0bNqRt27Z89dVXt5REcnIyq1evZtCgQfTp06fCfpmZmaSlpeHk5ES/fv0s2gMCAvD09CQ7O5vk5GTT9qKiIlNBHDx4sEWct7c3/v7+FBUVsXv3brM248x+0KBBFnFubm6mfG88A2D83trxHBwcGDBggNU4ERGR8mwu1MuWLaNnz558+umnDBkyxKL9vvvuIz09vcoJFBYWMnv2bBo0aMDrr79ead8jR44A0K5dO6vXkgE6d+4MwOHDh03bTp48SUFBAQ0aNKBly5aVxhmPAZCXl8fp06cB6NKli9U44/byxyv/fVXjREREyrO5UP/0009mp35v1KhRIy5evFjlBObPn8/Jkyd54403aNiwYaV9z549C0CzZs0q7GNsM/b9NXHnzp0DwN3dvcLT8V5eXhZxeXl55ObmAtC8eXObjyciInIjm28mc3Fx4erVqxW2nzlz5qaF9kZJSUmsWbOGoKAg06ngyly5cgWAevXqVdjH2Gbsa2ucq6srAPn5+aZtxp/Xlrjyxys/ThXN/K3lWZFbOVNRkatXrtp1f7WZxtH+NKbVQ+Nqf79mTDt06FCl/jYX6sDAQDZu3GhxNzXAzz//zLp16+jbt6/NBy4oKGD27NnUr1/fdBOYWFfVf9TK1HOtZ9f91Vbp6ekaRzvTmFYPjav93e4xtfnU90svvUR2djYhISHExsZiMBjYs2cPERERjBw5kjp16hAaGmrzgaOiosjIyODPf/6zzQt/GGevlc3sjW3GvrbGGWe29evXN20zznptiSt/vPIz8IKCApvzFBERuZHNM+rWrVuzaNEi/vrXv7Jo0SLKyspYvXo1AN27d2fatGmVXgO+UVxcHHXq1GHTpk1s2rTJrO2nn34CIDY2lu+++46WLVvyzjvvmK73nj9/vsL9ZmZmAubXhn9t3OXLl8nLy7N6nTorKwuAFi1amLa5ubnRoEEDcnNzOXfunNW/vKwdT0RE5EZVWvCkbdu2fPrpp+Tm5nL69GlKS0vx9vamUaNGt3Tw0tJSEhISKmw/c+YMZ86cMT3b3KlTJwCOHz9OQUGB1eu/KSkpZn0B2rRpg7Ozsylva3d+W4tzc3OjZcuWnD59mpSUFHr27GkR9+OPPwLQsWNHs+2dOnUiPj6elJQUq4XaGFf+eCIiIjeq0oInRg0aNKBLly74+fndcpH+97//zQ8//GD1P+PjX5MmTeKHH35g1apVwPU7rH19fSkqKmL79u0W+0xISCArKwsPDw/8/f1N252cnOjVqxdwfdGWG505c4ZDhw7h5ORE7969zdqM1923bNliEZeXl8e3334LXH+7mLU4a8crKSkxLQ5zY5yIiEh5VSrUly9fZuHChYwePZr+/fvTv39/Ro8ezcKFC02PI1W3kJAQACIiIsjIyDBtz8nJYd68eaY+N671HRISgsFgIDo62jSbhevXmN9//31KS0sJDg7G3d3dLG7kyJE4OzuzadMmdu3aZdpeXFxMWFgY+fn5BAUF0a5dO7O4oUOH4uHhwYEDB/jiiy/M2iIjIzl9+jSdOnUy/QEhIiJijc2nvjMyMnj55ZfJysqiXbt2dO/eHbi+7vfSpUvZsGEDUVFRZst6Vod+/foRHBxMbGwszz77LD169MDR0ZH4+HhT0Xz66act4rp06cIrr7xCREQE48ePJzAwEDc3NxITE8nJycHPz4+XX37ZIs7Ly4t33nmHWbNm8eabb5q9lOPcuXO0atWK6dOnW8S5urrywQcfMHnyZMLDw9mwYQOtW7cmPT2dEydO0LBhQ+bMmaN1vkVEpFI2F+rw8HDy8vKIjIwkMDDQrC0+Pp6pU6fy8ccf88knn9g9yRtNmzaNrl27EhMTQ2JiIiUlJbRp0+amr7kcM2YMHTp0YNWqVaSkpHDt2jVatGjB8OHDK33N5aBBg/D29mb58uUkJSXx448/4uXlxahRoyp9zWVAQAArV65k8eLFxMfHc+zYMRo3bszvf/97QkND9ZpLERG5KcPFixcrfp9kOX379mXUqFFMmDDBavvChQtZtWqV2elhufOGTZlDnP9Y0/eDj61hzZzKl2qVm9OzqfanMa0eGlf7q7HPUbu7u1tcv61Ku4iIiFSdzYV62LBhrF+/3myJTaO8vDzWr1/PsGHD7JqciIhIbVfhNeob3y3t4+ODwWDgj3/8I0OGDDE9i5yRkcFXX31F48aN8fHxqd5sRUREapkKC/U777yDwWAwvXe6/Nf//Oc/Lfrn5OQwc+ZMq+9tFhERkVtTYaGeP3/+7cxDRERErKiwUAcEBNzOPERERMSKW1pCVERERG6PKr2U48CBA6xfv56zZ89WuGTo559/bpfEREREpAqFeuXKlURERFC3bl18fHxo3LhxdeYlIiIiVLFQ33///fz1r3+tcMlMERERsS+br1EXFhYyePBgFWkREZHbyOZCHRgYSHp6enXmIiIiIjewuVC/+eabJCQksGLFCnJycqozJxEREfn/bL5G7enpyZNPPklERATz58/H0dHR4l3KBoNBb88SERGxI5sLdVRUFNHR0TRt2pTOnTvrWrWIiMhtYHOhXrduHY888ggffvghdeponRQREZHbweaKW1xcTK9evVSkRUREbiObq+4jjzxCQkJCdeYiIiIiN7C5UL/wwgv89NNP/OUvfyE5OZkLFy6Qk5Nj8Z+IiIjYj83XqJ955hkA0tPTWb9+fYX99u3b9+uzEhEREaAKhXrcuHEWj2OJiIhI9bK5UE+YMKE68xARERErdAu3iIhIDWbzjHrx4sU37WMwGBg3btyvSkhERET+x+ZCvWjRogrbDAYDZWVlKtQiIiJ2ZnOh/v777y22lZaWcu7cOWJiYkhMTOTvf/+7XZMTERGp7X7VNeo6derg7e3N5MmTadWqFR999JG98hIRERHseDNZt27d2LNnj712JyIiItixUKempmodcBERETuz+Rr1pk2brG7Py8sjMTGRnTt3MmzYMLslJiIiIlUo1O+9916FbQ0bNiQkJKTKd3wXFxeTkJDAnj17SEhIICMjg8LCQho1aoS/vz9PP/003bt3rzB+8+bNxMbGcvToUUpLS/Hx8WHo0KEEBwdXOrvfu3cvq1evJjU1lcLCQry9vRk4cCCjRo2ibt26FcYlJyezYsUKkpKSyM/Px8vLi6CgIF544YVK38998uRJlixZwv79+7l06RIeHh706tWL8ePH06RJE9sGS0REaqUqvY/6RgaDAXd3d+rXr39LB09ISGDixIkAeHh48MADD1CvXj1OnDjBjh072LFjB+PGjePFF1+0iP3www+JiYnB2dmZwMBAHB0d2b9/P+Hh4cTHxxMWFma1WEdHRxMREYGDgwMBAQG4u7uTmJjIggUL+O6774iKisLFxcUibsuWLcyaNYuSkhK6du1K06ZNSU5OZuXKlcTFxbFo0SIaN25s9WecPHkyhYWF+Pr60q1bN9LT0/nyyy/ZuXMnn332GT4+Prc0fiIicvezuVA3b97c7gc3GAw8/vjjPPPMM3Tr1s2sbevWrcyYMYMlS5bQvXt3AgMDTW07duwgJiYGDw8PFi5cSOvWrQHIzs7m5Zdf5ptvvmHt2rWMGDHCbJ8pKSlERkbi4uJCVFQUfn5+AFy5coXXXnuNxMREoqKimDJlillcZmYmc+bMoaysjPDwcIKCgoDrZwRmzpzJ1q1bmTt3LuHh4WZxV69e5e2336awsJA33niD4cOHm9o++eQTVq1axbvvvsuKFSu0jrqIiFh1R+/+6tGjB2FhYRZFGmDAgAEMGTIEgK+//tqsbfny5QBMnDjRVKTh+qx82rRpAKxYsYLS0lKzuOjoaMrKyhgzZoypSAO4uroyY8YM6tSpQ2xsLJcvXzaLW7NmDYWFhQwZMsRUpAEcHR2ZPn069evXJy4ujuPHj5vFbdiwgezsbLp3725WpI25t2zZkrS0NN0tLyIiFap0Rv3UU09VaWcGg4F//etfvyqh8jp16gRAVlaWaVtmZiZpaWk4OTnRr18/i5iAgAA8PT3JysoiOTmZ+++/H4CioiJTQRw8eLBFnLe3N/7+/hw8eJDdu3eb9YmLiwNg0KBBFnFubm706dOHzZs3ExcXR7t27SzirB3PwcGBAQMGsGzZMuLi4ujdu/fNB0RERGqdSgt127ZtbTole/78eY4dO2b307cZGRkAZjdcHTlyBIB27dpZvZYM0LlzZ7Kysjh8+LCpUJ88eZKCggIaNGhAy5YtK4w7ePAgR44cMRXXvLw8Tp8+DUCXLl2sxnXp0oXNmzdz+PBhs+3G7yuLK99PRETkRpUW6r/97W+VBp8/f56lS5fy/fffU7duXZ588km7JXbhwgU2btwIwOOPP27afvbsWQCaNWtWYayxzdj318SdO3cOAHd39wrv7Pby8rKIy8vLIzc3F6j4+r6144mIiJRn881k5WVmZrJ06VLTs9VPPfUUISEheHp62iUp401aeXl59OjRgz59+pjarly5AkC9evUqjDe2GfvaGufq6gpAfn6+advVq1dtjit/PGMcUOHM31qeIiIi5VWpUGdmZrJs2TLTTPfJJ5/k+eeft1uBNgoLCyM+Ph4vLy9mz55t133/FqWnp9ttX1evXLXr/mozjaP9aUyrh8bV/n7NmHbo0KFK/W0q1DcW6KFDh/L888+bTvna08cff8z69evx8PAgMjLSYkEQ4+y1/Iz1RsY2Y19b44wz2/LPhRtnvbbElT9e+Rl4QUGB1dPm1vK0pqr/qJWp51rPrvurrdLT0zWOdqYxrR4aV/u73WNaaaHOzMxk+fLlbNy4kbKysmot0AB///vf+fzzz2nUqBGRkZFmj14ZGa/3nj9/vtK8y/e1R9zly5fJy8uzWnCNd6W3aNHCtM3NzY0GDRqQm5vLuXPnrP6jWjueiIhIeZUW6uDgYIqLi+nYsSMhISE0a9aMCxcucOHChQpj7rvvvltK5B//+AerV6/mnnvuISIiwuwxp/KMj2wdP36cgoICq9d/U1JSzPoCtGnTBmdnZ3Jzczl9+rTVO7+txbm5udGyZUtOnz5NSkoKPXv2tIj78ccfAejYsaNFrvHx8aSkpFgt1Ma48scTEREpr9JCXVRUBFx/fOjtt9+udEdlZWUYDAb27dtX5SQiIiJYuXIlDRo0ICIiotJTCl5eXvj6+pKWlsb27dtNi6IYJSQkkJWVhYeHB/7+/qbtTk5O9OrVi507d7J582bGjx9vFnfmzBkOHTqEk5OTxTPNffv2ZfXq1WzZssWiUOfl5fHtt98C8Oijj1rExcfHs3nzZosXlpSUlLB161arcSIiIkaVFup333232hOYP38+0dHRuLu78+mnn9o0uwwJCWH69OlERERw//3306pVKwBycnKYN2+eqc+Na32HhITwzTffEB0dzcMPP2ya/V+5coX333+f0tJShg8fjru7u1ncyJEjiY2NZdOmTQQFBdG3b1/g+t3pYWFh5OfnExQUZHEWYOjQoSxfvpwDBw7wxRdf8PTTT5vaIiMjOX36NJ06daJXr15VHDUREaktDBcvXiy7UwfftWsXb7zxBnB9sZGKTne3adOGkJAQs23z5s0jNjYWZ2dnevTogaOjI/Hx8aaiGRYWhoODg8W+yr+UIzAwEDc3NxITE8nJycHPz++mL+UoLS01eynHuXPnaNWqlc0v5WjdujXp6emcOHGChg0bsmjRomp9KcewKXOI8x9r+n7wsTWsmfN6tR2vttANOvanMa0eGlf7q1E3k1U344IgAKmpqaSmplrtFxAQYFGop02bRteuXYmJiSExMZGSkhLatGlz09dcjhkzhg4dOrBq1SpSUlK4du0aLVq0YPjw4ZW+5nLQoEF4e3uzfPlykpKS+PHHH/Hy8mLUqFGVvuYyICCAlStXsnjxYuLj4zl27BiNGzfm97//PaGhoXrNpYiIVOqOzqil+mlGXT00S7E/jWn10Lja3+0e0zv69iwRERGpnAq1iIhIDaZCLSIiUoOpUIuIiNRgKtQiIiI1mAq1iIhIDaZCLSIiUoOpUIuIiNRgKtQiIiI1mAq1iIhIDaZCLSIiUoOpUIuIiNRgKtQiIiI1mAq1iIhIDaZCLSIiUoOpUIuIiNRgKtQiIiI1mAq1iIhIDaZCLSIiUoOpUIuIiNRgKtQiIiI1mAq1iIhIDaZCLSIiUoOpUIuIiNRgKtQiIiI1mAq1iIhIDaZCLSIiUoOpUIuIiNRgKtQiIiI1mAq1iIhIDeZ4pxOoLTZv3kxsbCxHjx6ltLQUHx8fhg4dSnBwMHXq6O8lERGxToX6Nvjwww+JiYnB2dmZwMBAHB0d2b9/P+Hh4cTHxxMWFqZiLSIiVqlQV7MdO3YQExODh4cHCxcupHXr1gBkZ2fz8ssv880337B27VpGjBhxhzMVEZGaSNO4arZ8+XIAJk6caCrSAB4eHkybNg2AFStWUFpaeifSExGRGk6FuhplZmaSlpaGk5MT/fr1s2gPCAjA09OT7OxskpOT70CGIiJS0+nUdzU6cuQIAO3atcPFxcVqn86dO5OVlcXhw4e5//77b2d6vP3X+RzLuWL6/t7Grnww5aXbmoOIiFROhboanT17FoBmzZpV2MfYZuxb3X46dowR73wMwImMsxx+dIqpzfc/H3Ds/7flnPmJxt5tABVwEZE7SYW6Gl25cn22Wq9evQr7GNuMfe3t3399x3zD2KiKO1fWJmY6dOhwp1O462hMq4fG1f5u95jqGrWIiEgNpkJdjVxdXQG4evVqhX2Mbca+IiIi5alQV6PmzZsDcP78+Qr7ZGZmmvUVEREpT4W6GnXq1AmA48ePU1BQYLVPSkqKWV8REZHydDNZNfLy8sLX15e0tDS2b9/OkCFDzNoTEhLIysrCw8MDf39/ux5ba4vbrri4mISEBPbs2UNCQgIZGRkUFhbSqFEj/P39efrpp+nevbtF3OzZs9m0aVOF+/Xx8eGLL76oztRrvFsdo9LSUmJjY9mwYQMnT56kTp06tG/fnj/+8Y8MGjSoOlOu0Q4cOMBLL9n2BMb69etNT5XodxVOnjzJ3r17SUlJITU1lVOnTlFWVsbcuXOtrnNR3q1+nu7du5fVq1eTmppKYWEh3t7eDBw4kFGjRlG3bl2bc1ehrmYhISFMnz6diIgI7r//flq1agVATk4O8+bNM/WxZ/HU2uJVk5CQwMSJE4HrK8Y98MAD1KtXjxMnTrBjxw527NjBuHHjePHFF63Gd+3alZYtW1psb9KkSbXm/VtSlTEqKSlh2rRp7Nq1i/r16/Pggw9SVFREfHw87777LsnJybz++uu3I+0ax8PDw+IP/vJSUlI4ceIELVu2xMvLy6K9Nv+uxsbGsmbNmirH3ernaXR0NBERETg4OBAQEIC7uzuJiYksWLCA7777jqioqArX17iRCnU169evH8HBwcTGxvLss8/So0cPHB0diY+PJz8/n6CgIJ5++mm7HU9ri1edwWDg8ccf55lnnqFbt25mbVu3bmXGjBksWbKE7t27ExgYaBE/bNgwnnjiiduV7m9SVcZozZo17Nq1i7Zt2xIVFYWHhwcAp06dYsKECXz++ecEBgYSFBRUnSnXSG3atGHmzJkVtj/zzDMADB06FIPBYNFem39X27Vrx6hRo+jcuTOdO3dmzpw5JCQkVBpzq5+nKSkpREZG4uLiQlRUFH5+fsD1x3Bfe+01EhMTiYqKYsqUKRbHtEbTqttg2rRpvPfee3Tq1InExET27dtHq1atePPNN5k3bx4ODg52O5bWFq+6Hj16EBYWZlGkAQYMGGCawXz99de3O7Vap6SkhH/+85/A9f9vjEUaoHXr1qYzH8uWLbsj+dVkSUlJnDhxAgcHh1pbjCvz1FNPMWnSJAYMGGD1rII1t/p5Gh0dTVlZGWPGjDEVabj+dM+MGTOoU6cOsbGxXL582aY8VKhvk8GDB7N48WJ27tzJrl27iI6O5umnn7brKWitLV49jDf6ZWVl3eFM7n6HDh0iJycHT09PAgICLNr79++Po6MjKSkp+ve4wYYNGwB46KGHaNq06R3O5rfvVj9Pi4qK2LNnD3D9c/9G3t7e+Pv7U1RUxO7du23KRae+7yI1fW3x36qMjAyg4ut4+/fvJz09natXr9K4cWO6du3Kgw8+qPsAyrF1jA4fPgxAly5drO7HxcWFdu3aceTIESJuuEUAAAjSSURBVI4cOYKnp2e15/5bUFBQwLZt2wB48sknK+yn31Xb3ern6cmTJykoKKBBgwYVztw7d+7MwYMHOXLkiNVifiMV6rtITVxb/LfuwoULbNy4EYDHH3/cap+vvvrKYlvbtm354IMPaN++fbXm91th6xjZ+jt85MgR/Q6Xs23bNvLz82ncuDF9+vSpsJ9+V213q5+n1fE5rEJ9F6kJa4vfTYqLi5k5cyZ5eXn06NHD4gOwY8eO+Pr60rNnT5o1a0Z+fj5paWnMnz+f9PR0Jk6cSHR0dK2e9VV1jIwr9el3uGqMp73/z//5Pzg6Wn6s63e16m7189SWOONKlPn5+TblovMdIhUICwsjPj4eLy8vZs+ebdE+cuRInnnmGdq2bUu9evVo0qQJjzzyCMuXL8fPz4+cnBxWrFhxBzKvOTRG1S8jI4PExETg+t3e1ujf4bdNhfouorXF7efjjz9m/fr1eHh4EBkZWaXnTJ2cnHj++ecBbL5ZpLapaIyMsxD9DtvOOJv29/enbdu2VYrV72rFbvXz1JY446y7fv36NuWiQn0X0dri9vH3v/+dzz//nEaNGhEZGWn2WIatfHx8APj555/tnd5dw9oYtWjRAtDvsK1KSkpM150ru4msMvpdte5WP0+r43NYhfouorXFf71//OMfrF69mnvuuYeIiAjatWt3S/u5dOkSUPl1qtrO2hgZfy+Nv6c3Kigo4NixY2Z9a7N9+/aRlZWFq6srAwYMuKV96HfVulv9PG3Tpg3Ozs7k5uZy+vRpm+Mqo0J9FzGuLV5UVMT27dst2qtzbfG7QUREBCtXrqRBgwZERET8qpfDGx+VqegxI7E+Rv7+/jRq1IisrCyrq0Zt27aN4uJiunTpohufuL6eN1xfAfFWLwXod9W6W/08dXJyolevXsD1NcJvdObMGQ4dOoSTkxO9e/e2KRcV6rtMSEgIcL3oGJ//hepdW/xuMH/+fKKjo3F3d+fTTz+96V+6R44c4dtvv6WkpMRse3FxMatWrWLt2rXA9Zt4aqtbGSMHBwdGjx4NwLx588jJyTG1nTp1isjISADGjh1b3enXeBcvXuTbb78Fri8NWhH9rt66W/08DQkJ+X/t3V9Ik+0fx/H39FeGmU0JC//UgsCkDnJsHZQHdRAS9g/UtA4GUQQlRZB5UlSsP1QnRlAERpJYYK1QGlIEUdsg2g6KZNWo1ZQISagNs5q0+TsQxhPl7+mpZ3r/7PM627VrN9d178+H+753X19MJhNtbW0Eg8FU+6dPnzhy5AjJZJLq6mpmzJjxU+MwRaPRkd+djBjLyZMnuX79OllZWT9cW/zEiRP/6rKl/+88Hg+NjY3A6EIEY53utlgsqS/uvXv3aGpqIjc3l4ULF5KXl0csFiMcDjMwMEBGRgYNDQ2p0PkT/eo+SiQSNDU14fV6mT59Ona7na9fvxIIBIjH42zcuDH1fv3Jrly5wunTp7FYLKmw/RF9Vkc9f/6cU6dOpR6/fv2aoaEhSkpKmDlzZqr94sWL37zuV39P/1qUw2azkZOTw6NHj3j//j2LFy/+R0U5FNST1K1bt3C5XITDYRKJBBaLRWUux+B2u3E6nX/bz2q1cv78eWD09FVHRwfBYJD+/n5isRgmk4mCggKWLFlCTU0NZWVl6R66of3OPkomk7hcLtxuN5FIhMzMTBYsWEB1dfVPreT0J9i8eTMvX75k165d/zNk9Vkd9bMlQv1+/3dtv/p7+uDBAy5fvsyzZ88YHh6msLCQysrKf1zmUkEtIiJiYDq0EhERMTAFtYiIiIEpqEVERAxMQS0iImJgCmoREREDU1CLiIgYmIJaRETEwBTUIiIiBqagFpHf5na7Wbp0KT09PRM9FJFJR0EtIiJiYApqERERA/vPRA9ARP4M0WiUc+fO4fF4+PjxI8XFxdTX17Nhw4Zv+t25c4f29nb6+voYGRmhoKCAyspKtm7dCoyWZ7x06RLd3d28e/eOrKwsSkpKcDgcrFy5ciKmJpJWCmoRSbt4PM6OHTuIRCLU1tZSVFTE/fv3OX78OLFYLFU+1O/3c+DAAWw2Gzt37iQjI4Pe3l4eP36c2taFCxdobW1l3bp1LFq0iM+fPxMKhQgGgwpqmZQU1CKSdp2dnYTDYQ4ePMiaNWsAqKmpYffu3bS0tLB+/XrMZjM+n4/s7GzOnDkzZs10n8/HsmXL2L9//3hOQWTC6Bq1iKSdz+cjLy+P1atXp9oyMzOpr69neHiYQCAAQE5ODl++fOHhw4djbisnJ4dXr17R29ub9nGLGIGCWkTSrr+/n+Li4u+OkufPnw/A27dvgdGj7Llz57Jnzx6qqqo4fPgwHo+HkZGR1Gu2b9/O0NAQtbW11NXV0dzczNOnT8dvMiLjTEEtIoaRn59Pe3s7zc3NrFixgp6eHhobG9m7d28qrK1WKzdu3ODQoUOUlpbS3d3Nli1baGtrm+DRi6SHglpE0m7OnDm8efOGRCLxTXskEgGgsLAw1TZlyhSWL1/Ovn37cLlcOBwOfD4fT548SfXJzc2lqqoKp9PJzZs3sVqttLS0fLd9kclAQS0iaVdRUcGHDx+4fft2qi2ZTNLR0cHUqVOx2+3A6C1cf2UymSgtLQVgcHDwh32mTZvGvHnziMfjxOPxdE5DZELoX98i8q9xu934/f7v2teuXUtnZydHjx4lFAqlbs8KBAI0NDRgNpsBOHbsGNFoFLvdzuzZsxkYGODatWvMmjWL8vJyAOrq6igvL6esrAyz2cyLFy/o6uqioqKC7OzscZ2vyHgwRaPRkb/vJiIyNrfbjdPpHPP5q1evYjabOXv2LF6vl8HBQYqLi9m0adM3C57cvXuXrq4uQqEQg4OD5OfnY7PZ2LZtG0VFRQC0trbi9Xrp6+sjHo9TUFDAqlWrcDgcCmqZlBTUIiIiBqZr1CIiIgamoBYRETEwBbWIiIiBKahFREQMTEEtIiJiYApqERERA1NQi4iIGJiCWkRExMAU1CIiIgamoBYRETGw/wLjv5Vz1D9kFgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1fe9f16cf8ed034ee3bb0e6fbd66f76f071746c2"
      },
      "cell_type": "code",
      "source": "# # Correlations between Features and Target\n\n# Find all correlations and sort \ncorrelations_data = data.corr()['loss'].sort_values()\n\n# Print the most negative correlations\nprint(correlations_data.head(15), '\\n')\n\n# Print the most positive correlations\nprint(correlations_data.tail(15))",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "f612   -0.016943\nf776   -0.015111\nf315   -0.011106\nf70    -0.010740\nf314   -0.010689\nf323   -0.010676\nf69    -0.010269\nf322   -0.009299\nf734   -0.009284\nf738   -0.008635\nf1     -0.008162\nf631   -0.008097\nf428   -0.007973\nf666   -0.007868\nf299   -0.007778\nName: loss, dtype: float64 \n\nf674    0.018999\nf536    0.026087\nf471    0.039538\nloss    1.000000\nf33          NaN\nf34          NaN\nf35          NaN\nf37          NaN\nf38          NaN\nf678         NaN\nf700         NaN\nf701         NaN\nf702         NaN\nf736         NaN\nf764         NaN\nName: loss, dtype: float64\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "61a89b14640fbc08f925bb29e6fa17ec9cc757af",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "for i in data.columns:\n    if len(set(data[i]))==1:\n        data.drop(labels=[i], axis=1, inplace=True)",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8e04f8eadeeab0cdfffa98923e49f95b4f89064c"
      },
      "cell_type": "code",
      "source": "# Find all correlations and sort \ncorrelations_data = data.corr()['loss'].sort_values()\n\n# Print the most negative correlations\nprint(correlations_data.head(15), '\\n')\n\n# Print the most positive correlations\nprint(correlations_data.tail(15))",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": "f612   -0.016943\nf776   -0.015111\nf315   -0.011106\nf70    -0.010740\nf314   -0.010689\nf323   -0.010676\nf69    -0.010269\nf322   -0.009299\nf734   -0.009284\nf738   -0.008635\nf1     -0.008162\nf631   -0.008097\nf428   -0.007973\nf666   -0.007868\nf299   -0.007778\nName: loss, dtype: float64 \n\nf282    0.010726\nf251    0.010915\nf221    0.010968\nf556    0.011575\nf675    0.011606\nf13     0.011933\nf68     0.013375\nf599    0.014165\nf597    0.014165\nf670    0.014811\nf67     0.015012\nf674    0.018999\nf536    0.026087\nf471    0.039538\nloss    1.000000\nName: loss, dtype: float64\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "668d758b12480015588a2dbf8a09268ac98adf08"
      },
      "cell_type": "code",
      "source": "data.shape",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "(103302, 741)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "19e87448a6d0ba70d09f1ceb9901b8b4cbdd07c8"
      },
      "cell_type": "code",
      "source": "# # # Feature Engineering and Selection\n\ndef remove_collinear_features(x, threshold):\n    '''\n    Objective:\n        Remove collinear features in a dataframe with a correlation coefficient\n        greater than the threshold. Removing collinear features can help a model\n        to generalize and improves the interpretability of the model.\n        \n    Inputs: \n        threshold: any features with correlations greater than this value are removed\n    \n    Output: \n        dataframe that contains only the non-highly-collinear features\n    '''\n    \n    # Dont want to remove correlations between loss\n    y = x['loss']\n    x = x.drop(columns = ['loss'])\n    \n    # Calculate the correlation matrix\n    corr_matrix = x.corr()\n    iters = range(len(corr_matrix.columns) - 1)\n    drop_cols = []\n\n    # Iterate through the correlation matrix and compare correlations\n    for i in iters:\n        for j in range(i):\n            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n            col = item.columns\n            row = item.index\n            val = abs(item.values)\n            \n            # If correlation exceeds the threshold\n            if val >= threshold:\n                # Print the correlated features and the correlation value\n                # print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n                drop_cols.append(col.values[0])\n\n    # Drop one of each pair of correlated columns\n    drops = set(drop_cols)\n    x = x.drop(columns = drops)\n    \n    # Add the score back in to the data\n    x['loss'] = y\n               \n    return x",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "72a9179d42f2c3e287655146b97b7a11fcd005ed"
      },
      "cell_type": "code",
      "source": "# Remove the collinear features above a specified correlation coefficient\ndata = remove_collinear_features(data, 0.6);",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0714bb6b8bfe04988becfd704daf41edf9b1043a"
      },
      "cell_type": "code",
      "source": "data.shape",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "(103302, 156)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e7ff6c82948ad99aee1b8c5025d4508fca9426f6",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# # # Split Into Training and Testing Sets\n\n# Separate out the features and targets\nfeatures = data.drop(columns='loss')\ntargets = pd.DataFrame(data['loss'])\n\n# Split into 80% training and 20% testing set\nX_train, X_test, y_train, y_test = train_test_split(features, targets, test_size = 0.2, random_state = 42)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(82641, 155)\n(20661, 155)\n(82641, 1)\n(20661, 1)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5e4416f1bb6e26b561922dae8c81670d70cc974c"
      },
      "cell_type": "code",
      "source": "# # Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\n/opt/conda/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n  return self.fit(X, **fit_params).transform(X)\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n  \"\"\"\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5defba707e03f4c369bfacfa358162774d86346d"
      },
      "cell_type": "code",
      "source": "# Convert y to one-dimensional array (vector)\ny_train = np.array(y_train).reshape((-1, ))\ny_test = np.array(y_test).reshape((-1, ))",
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "62df1f869bdcb157c0f242247ebaa2b61e3d227a"
      },
      "cell_type": "code",
      "source": "X_train",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "array([[-1.06877109, -0.16688215,  1.03564494, ..., -0.61327879,\n         0.65159233, -0.66443318],\n       [-0.48425848,  2.15138579, -0.14682708, ..., -0.86473327,\n         0.74503266, -0.66443318],\n       [-0.43576466,  1.60591098, -0.73806309, ...,  1.07833542,\n         1.24726226,  1.50504223],\n       ...,\n       [ 0.84197055, -0.57598826,  1.03564494, ...,  0.82039823,\n        -0.75457294,  1.50504223],\n       [-1.69955094, -0.64417261,  0.44440893, ..., -1.37936099,\n        -0.4115703 , -0.66443318],\n       [-1.20154789,  1.06043617, -0.14682708, ..., -0.67299456,\n         0.87515049, -0.66443318]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "354fe7c290ae7d708590aeede77a2e1f4ba10aa5"
      },
      "cell_type": "code",
      "source": "X_test",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "array([[-0.47027681, -1.18964742,  1.03564494, ...,  0.83261565,\n         4.19883151,  1.50504223],\n       [ 0.34727464,  1.67409533, -0.73806309, ..., -1.49355648,\n         0.76570014, -0.66443318],\n       [ 1.02805453, -0.3714352 , -2.51177113, ..., -0.96808269,\n         1.03078733,  1.50504223],\n       ...,\n       [ 0.29720911,  0.92406747, -0.73806309, ..., -1.16904681,\n        -0.70741614, -0.66443318],\n       [ 0.85975052, -0.91691001,  1.03564494, ..., -0.85600654,\n        -0.90497014,  1.50504223],\n       [ 0.00752321, -1.18964742, -1.3292991 , ..., -1.04126255,\n         0.69224809, -0.66443318]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "59165d3c0c09f25fa49a8b70e13e057a75ebd662"
      },
      "cell_type": "code",
      "source": "# # # Models to Evaluate\n\n# We will compare five different machine learning Cassification models:\n\n# 1 - Logistic Regression\n# 2 - K-Nearest Neighbors Classification\n# 3 - Suport Vector Machine\n# 4 - Naive Bayes\n# 5 - Random Forest Classification\n\n# Function to calculate mean absolute error\ndef cross_val(X_train, y_train, model):\n    # Applying k-Fold Cross Validation\n    from sklearn.model_selection import cross_val_score\n    accuracies = cross_val_score(estimator = model, X = X_train, y = y_train, cv = 5)\n    return accuracies.mean()\n\n# Takes in a model, trains the model, and evaluates the model on the test set\ndef fit_and_evaluate(model):\n    \n    # Train the model\n    model.fit(X_train, y_train)\n    \n    # Make predictions and evalute\n    model_pred = model.predict(X_test)\n    model_cross = cross_val(X_train, y_train, model)\n    \n    # Return the performance metric\n    return model_cross",
      "execution_count": 28,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a5d839ce0829f4d6205b69767b7fa84b0d547744"
      },
      "cell_type": "code",
      "source": "# # Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\nnaive = GaussianNB()\nnaive_cross = fit_and_evaluate(naive)\n\nprint('Naive Bayes Performance on the test set: Cross Validation Score = %0.4f' % naive_cross)",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n  % (min_groups, self.n_splits)), Warning)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Naive Bayes Performance on the test set: Cross Validation Score = 0.0099\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e90ced9e87d28f2532dd5f9856e41d59e52ed11b"
      },
      "cell_type": "code",
      "source": "# # Random Forest Classification\nfrom sklearn.ensemble import RandomForestClassifier\nrandom = RandomForestClassifier(n_estimators = 10, criterion = 'entropy')\nrandom_cross = fit_and_evaluate(random)\n\nprint('Random Forest Performance on the test set: Cross Validation Score = %0.4f' % random_cross)",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n  % (min_groups, self.n_splits)), Warning)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Random Forest Performance on the test set: Cross Validation Score = 0.9067\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "687f4e0ee16b1605f62da51937433c6b1fb1da19"
      },
      "cell_type": "code",
      "source": "# # Gradiente Boosting Classification\nfrom xgboost import XGBClassifier\ngb = XGBClassifier()\ngb_cross = fit_and_evaluate(gb)\n\nprint('Gradiente Boosting Classification Performance on the test set: Cross Validation Score = %0.4f' % gb_cross)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "64b9e4bc8bd315eccbb57e2b4fdc69497bc6414b"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "535f8320cd4758fd3c95c23eebca4d64da87f192"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "da59ddb65c4111fcf40bad22703b180ad40816ee"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}